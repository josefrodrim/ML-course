{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fba03f03",
   "metadata": {},
   "source": [
    "#  Masterclass: Regresion \n",
    "### Prediccion de **ingreso_mensual** (Regresion) con validacion temporal, rolling window y reentrenamiento automatico  \n",
    "## Autor / Instructor: **Josef Rodriguez**\n",
    "\n",
    "---\n",
    "\n",
    "## Objetivo del notebook\n",
    "Construir un flujo completo (tipo industria) para un problema de **regresion** con datos mensuales:\n",
    "\n",
    "- Dataset realista con `codmes` (YYYYMM) desde 202201 hasta 202602\n",
    "- EDA + correlacion\n",
    "- Multicolinealidad con **VIF**\n",
    "- Split temporal: backtesting (2022), train/test (2023-2025) y OOT (2026+)\n",
    "- Modelos: lineales + regularizacion + no lineales\n",
    "- **Cross-validation temporal**\n",
    "- **Rolling window backtest**\n",
    "- Feature importance comparada (coeficientes + permutation importance)\n",
    "- **SHAP** (si esta instalado)\n",
    "- **Walk-forward** (reentrenamiento automatico mensual) con metricas mes a mes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c50af535",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================\n",
    "# 1) LIBRERIAS\n",
    "# ==============================\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "pd.set_option(\"display.max_columns\", 200)\n",
    "pd.set_option(\"display.width\", 140)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c73afba",
   "metadata": {},
   "source": [
    "## 2) Dataset (formato realista)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "935bcb91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================\n",
    "# 2) CARGA DEL DATASET DESDE GITHUB\n",
    "# ==============================\n",
    "# Nota:\n",
    "# - Para notebooks, se recomienda usar el enlace RAW (raw.githubusercontent.com)\n",
    "# - Asi los alumnos no necesitan descargar archivos manualmente\n",
    "# - Funciona en Colab, Jupyter y VS Code\n",
    "\n",
    "url = \"https://raw.githubusercontent.com/josefrodrim/ML-course/main/data/ridetech_peru_regression_202201_202602.csv\"\n",
    "\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "print(\"Dataset cargado correctamente desde GitHub\")\n",
    "print(\"Shape:\", df.shape)\n",
    "print(\"Rango codmes:\", df[\"codmes\"].min(), \"->\", df[\"codmes\"].max())\n",
    "\n",
    "# Orden temporal recomendado\n",
    "df = df.sort_values([\"codmes\",\"driver_id\"]).reset_index(drop=True)\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd316f4f",
   "metadata": {},
   "source": [
    "## 3) Definicion de variables (col_num / col_cat / target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8423a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================\n",
    "# 3) VARIABLES\n",
    "# ==============================\n",
    "target = \"ingreso_mensual\"\n",
    "\n",
    "col_num = [\n",
    "    \"antiguedad_meses\",\"horas_conectado\",\"viajes_realizados\",\"rating_promedio\",\n",
    "    \"cancelaciones_pct\",\"precio_promedio_viaje\",\"incentivo_bono\",\"combustible_indice\"\n",
    "]\n",
    "\n",
    "col_cat = []  # (placeholder) puedes agregar 'ciudad' en futuras clases y hacer OneHotEncoder\n",
    "col_id  = [\"driver_id\",\"codmes\"]\n",
    "\n",
    "print(\"Target:\", target)\n",
    "print(\"Numericas:\", col_num)\n",
    "print(\"Categoricas:\", col_cat)\n",
    "print(\"IDs:\", col_id)\n",
    "print(\"Rango codmes:\", df[\"codmes\"].min(), \"\", df[\"codmes\"].max())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34085fe9",
   "metadata": {},
   "source": [
    "## 4) EDA basico: distribucion, correlacion y serie temporal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0af8955",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================\n",
    "# 4) EDA\n",
    "# ==============================\n",
    "# 4.1 Distribucion del target\n",
    "plt.figure()\n",
    "plt.hist(df[target], bins=40)\n",
    "plt.title(\"Distribucion de ingreso_mensual\")\n",
    "plt.xlabel(\"ingreso_mensual\")\n",
    "plt.ylabel(\"frecuencia\")\n",
    "plt.show()\n",
    "\n",
    "# 4.2 Evolucion del target promedio por mes\n",
    "ts = df.groupby(\"codmes\")[target].mean().reset_index()\n",
    "plt.figure()\n",
    "plt.plot(ts[\"codmes\"], ts[target])\n",
    "plt.xticks(rotation=90)\n",
    "plt.title(\"Ingreso mensual promedio por codmes\")\n",
    "plt.xlabel(\"codmes\")\n",
    "plt.ylabel(\"promedio ingreso_mensual\")\n",
    "plt.show()\n",
    "\n",
    "# 4.3 Correlacion (solo numericas + target)\n",
    "corr = df[col_num + [target]].corr().values\n",
    "labels = col_num + [target]\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.imshow(corr)\n",
    "plt.xticks(range(len(labels)), labels, rotation=90)\n",
    "plt.yticks(range(len(labels)), labels)\n",
    "plt.title(\"Matriz de correlacion\")\n",
    "plt.colorbar()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1c15edf",
   "metadata": {},
   "source": [
    "## 5) Multicolinealidad: VIF (Variance Inflation Factor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4057ead4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================\n",
    "# 5) VIF\n",
    "# ==============================\n",
    "# Interpretacion rapida (regla practica):\n",
    "# - VIF ~ 1: sin colinealidad\n",
    "# - VIF 5-10: colinealidad moderada/alta\n",
    "# - VIF > 10: potencial problema (coeficientes inestables en modelos lineales)\n",
    "\n",
    "def compute_vif(df_num: pd.DataFrame) -> pd.DataFrame:\n",
    "    X = sm.add_constant(df_num)  # agrega intercepto\n",
    "    out = []\n",
    "    for i in range(1, X.shape[1]):  # saltar const\n",
    "        out.append((X.columns[i], variance_inflation_factor(X.values, i)))\n",
    "    return pd.DataFrame(out, columns=[\"feature\",\"VIF\"]).sort_values(\"VIF\", ascending=False)\n",
    "\n",
    "vif_table = compute_vif(df[col_num])\n",
    "vif_table\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac6b7e50",
   "metadata": {},
   "source": [
    "Analisis de Multicolinealidad (VIF)\n",
    "\n",
    "La tabla muestra los valores del Variance Inflation Factor (VIF) para cada variable numerica del modelo.\n",
    "\n",
    "Los resultados indican que todos los VIF se encuentran aproximadamente entre 1.00 y 1.33, lo que implica un nivel muy bajo de multicolinealidad entre las variables explicativas.\n",
    "\n",
    "En terminos practicos:\n",
    "\n",
    "Un VIF cercano a 1 indica ausencia de colinealidad.\n",
    "\n",
    "Valores entre 5 y 10 suelen considerarse problematicos.\n",
    "\n",
    "Valores mayores a 10 indican multicolinealidad severa.\n",
    "\n",
    "En este caso, ninguna variable presenta valores que sugieran riesgo estadistico. Esto significa que las variables no estan altamente correlacionadas entre si y, por tanto, los coeficientes de los modelos lineales deberian ser estables.\n",
    "\n",
    "Aunque la multicolinealidad no es un problema relevante en este dataset, el ejercicio sigue siendo importante porque en contextos reales (especialmente financieros o macroeconomicos) es comun encontrar VIF elevados. La regularizacion (Ridge o ElasticNet) es una estrategia adecuada cuando se detecta este problema.\n",
    "\n",
    "En conclusion, el conjunto de variables numericas es apropiado para modelamiento lineal sin necesidad de eliminar variables por colinealidad."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58b8a4c4",
   "metadata": {},
   "source": [
    "## 6) Split temporal (train / test / oot y backtesting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "957dd531",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================\n",
    "# 6) SPLIT TEMPORAL (BACK + TRAIN/TEST + OOT)\n",
    "# ==============================\n",
    "# Definiciones:\n",
    "# - back: 202201-202212 (backtesting historico)\n",
    "# - train: 202301-202412 (entrenamiento)\n",
    "# - test: 202501-202512 (test temporal dentro de historico reciente)\n",
    "# - oot:  202601 en adelante (out-of-time / produccion simulada)\n",
    "\n",
    "back = df[(df.codmes >= 202201) & (df.codmes <= 202212)].copy()\n",
    "train = df[(df.codmes >= 202301) & (df.codmes <= 202412)].copy()\n",
    "test  = df[(df.codmes >= 202501) & (df.codmes <= 202512)].copy()\n",
    "oot   = df[df.codmes >= 202601].copy()\n",
    "\n",
    "X_back, y_back = back[col_num], back[target]\n",
    "X_train, y_train = train[col_num], train[target]\n",
    "X_test,  y_test  = test[col_num],  test[target]\n",
    "X_oot,   y_oot   = oot[col_num],   oot[target]\n",
    "\n",
    "print(\"Back :\", back[\"codmes\"].min(), \"->\", back[\"codmes\"].max(), \"| rows:\", len(back))\n",
    "print(\"Train:\", train[\"codmes\"].min(), \"->\", train[\"codmes\"].max(), \"| rows:\", len(train))\n",
    "print(\"Test :\", test[\"codmes\"].min(), \"->\", test[\"codmes\"].max(), \"| rows:\", len(test))\n",
    "print(\"OOT  :\", oot[\"codmes\"].min(),  \"->\", oot[\"codmes\"].max(),  \"| rows:\", len(oot))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "267ac07e",
   "metadata": {},
   "source": [
    "## 7) Funciones de evaluacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "529763fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================\n",
    "# 7) METRICAS\n",
    "# ==============================\n",
    "def metrics(y_true, y_pred):\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    return mae, rmse, r2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d09ceba",
   "metadata": {},
   "source": [
    "## 8) Modelos de regresion (incluye regularizacion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b03ccca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================\n",
    "# 8) DEFINICION DE MODELOS\n",
    "# ==============================\n",
    "\n",
    "# Se definen distintos algoritmos de regresion para comparar desempeño.\n",
    "# Incluimos:\n",
    "# - Modelos lineales clasicos\n",
    "# - Modelos con regularizacion (L1, L2, ElasticNet)\n",
    "# - Modelos no lineales basados en arboles\n",
    "\n",
    "models = {\n",
    "\n",
    "    # 1) Regresion Lineal clasica (OLS)\n",
    "    # No incluye regularizacion.\n",
    "    # Sirve como baseline interpretable.\n",
    "    \"Linear\": LinearRegression(),\n",
    "\n",
    "    # 2) Ridge Regression (L2)\n",
    "    # Penaliza el cuadrado de los coeficientes.\n",
    "    # Reduce varianza y estabiliza coeficientes ante colinealidad.\n",
    "    \"Ridge(alpha=10)\": Ridge(alpha=10),\n",
    "\n",
    "    # 3) Lasso Regression (L1)\n",
    "    # Penaliza el valor absoluto de los coeficientes.\n",
    "    # Puede llevar algunos coeficientes exactamente a cero (seleccion de variables).\n",
    "    \"Lasso(alpha=0.1)\": Lasso(alpha=0.1),\n",
    "\n",
    "    # 4) ElasticNet (combinacion L1 + L2)\n",
    "    # Combina estabilidad (L2) y seleccion (L1).\n",
    "    # l1_ratio controla el balance entre ambas penalizaciones.\n",
    "    \"ElasticNet(a=0.1,l1=0.5)\": ElasticNet(alpha=0.1, l1_ratio=0.5),\n",
    "\n",
    "    # 5) RandomForest\n",
    "    # Ensamble de multiples arboles entrenados en paralelo.\n",
    "    # Captura no linealidades e interacciones automaticamente.\n",
    "    # Robusto a outliers y a relaciones complejas.\n",
    "    \"RandomForest\": RandomForestRegressor(\n",
    "        n_estimators=350,     # numero de arboles\n",
    "        random_state=42,      # reproducibilidad\n",
    "        n_jobs=-1             # uso de todos los nucleos\n",
    "    ),\n",
    "\n",
    "    # 6) Gradient Boosting\n",
    "    # Ensamble secuencial donde cada arbol corrige errores del anterior.\n",
    "    # Suele tener mayor precision predictiva que RF en muchos escenarios.\n",
    "    \"GradientBoosting\": GradientBoostingRegressor(\n",
    "        random_state=42\n",
    "    )\n",
    "}\n",
    "\n",
    "# Conjunto auxiliar que identifica los modelos lineales.\n",
    "# Se usa mas adelante para aplicar StandardScaler solo a modelos que lo necesitan.\n",
    "linear_names = {\n",
    "    \"Linear\",\n",
    "    \"Ridge(alpha=10)\",\n",
    "    \"Lasso(alpha=0.1)\",\n",
    "    \"ElasticNet(a=0.1,l1=0.5)\"\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2740ed04",
   "metadata": {},
   "source": [
    "## 9) Entrenamiento y evaluacion global (Validation + Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cae45c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================\n",
    "# 9) EVALUACION GLOBAL (TEST + OOT)\n",
    "# ==============================\n",
    "\n",
    "# Lista donde almacenaremos los resultados finales\n",
    "rows = []\n",
    "\n",
    "# Diccionario para guardar los modelos ya entrenados\n",
    "# Esto nos permitirá reutilizarlos luego (SHAP, importancia, etc.)\n",
    "fitted = {}\n",
    "\n",
    "# Iteramos sobre cada modelo definido previamente\n",
    "for name, model in models.items():\n",
    "    \n",
    "    # ---------------------------------------------------------\n",
    "    # 1) Construccion del Pipeline\n",
    "    # ---------------------------------------------------------\n",
    "    # Los modelos lineales requieren estandarizacion,\n",
    "    # ya que son sensibles a la escala de las variables.\n",
    "    # Los modelos basados en arboles no lo necesitan.\n",
    "    \n",
    "    if name in linear_names:\n",
    "        pipe = Pipeline([\n",
    "            (\"scaler\", StandardScaler()),   # estandarizacion Z-score\n",
    "            (\"model\", model)\n",
    "        ])\n",
    "    else:\n",
    "        pipe = Pipeline([\n",
    "            (\"model\", model)                # sin escalamiento\n",
    "        ])\n",
    "        \n",
    "    # ---------------------------------------------------------\n",
    "    # 2) Entrenamiento (solo con TRAIN)\n",
    "    # ---------------------------------------------------------\n",
    "    pipe.fit(X_train, y_train)\n",
    "    \n",
    "    # Guardamos el modelo entrenado\n",
    "    fitted[name] = pipe\n",
    "    \n",
    "    # ---------------------------------------------------------\n",
    "    # 3) Predicciones\n",
    "    # ---------------------------------------------------------\n",
    "    # Evaluamos sobre:\n",
    "    # - Test (periodo posterior dentro del rango historico)\n",
    "    # - OOT  (periodo completamente fuera de muestra)\n",
    "    \n",
    "    pred_test = pipe.predict(X_test)\n",
    "    pred_oot  = pipe.predict(X_oot)\n",
    "    \n",
    "    # ---------------------------------------------------------\n",
    "    # 4) Metricas\n",
    "    # ---------------------------------------------------------\n",
    "    # Calculamos:\n",
    "    # - MAE  (error absoluto medio)\n",
    "    # - RMSE (error cuadratico medio)\n",
    "    # - R2   (capacidad explicativa)\n",
    "    \n",
    "    mae_te, rmse_te, r2_te = metrics(y_test, pred_test)\n",
    "    mae_oo, rmse_oo, r2_oo = metrics(y_oot, pred_oot)\n",
    "    \n",
    "    # Guardamos resultados\n",
    "    rows.append([\n",
    "        name,\n",
    "        mae_te, rmse_te, r2_te,\n",
    "        mae_oo, rmse_oo, r2_oo\n",
    "    ])\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 5) Construccion del DataFrame final\n",
    "# ---------------------------------------------------------\n",
    "# Ordenamos por menor MAE en Test\n",
    "res = pd.DataFrame(\n",
    "    rows,\n",
    "    columns=[\n",
    "        \"modelo\",\n",
    "        \"MAE_test\", \"RMSE_test\", \"R2_test\",\n",
    "        \"MAE_oot\",  \"RMSE_oot\",  \"R2_oot\"\n",
    "    ]\n",
    ").sort_values(\"MAE_test\")\n",
    "\n",
    "res\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c63d040",
   "metadata": {},
   "source": [
    "## Comparacion de Modelos - Evaluacion en Test y OOT\n",
    "\n",
    "### Desempeño en Test (Periodo 2025)\n",
    "\n",
    "| Modelo                     | MAE    | RMSE   | R2     |\n",
    "|----------------------------|--------|--------|--------|\n",
    "| GradientBoosting           | 269.45 | 337.75 | 0.9396 |\n",
    "| RandomForest               | 278.64 | 349.48 | 0.9353 |\n",
    "| Linear                     | 296.80 | 374.68 | 0.9257 |\n",
    "| Lasso (alpha=0.1)          | 296.81 | 374.69 | 0.9257 |\n",
    "| Ridge (alpha=10)           | 296.83 | 374.73 | 0.9257 |\n",
    "| ElasticNet (a=0.1, l1=0.5) | 303.57 | 384.31 | 0.9218 |\n",
    "\n",
    "**Analisis:**\n",
    "\n",
    "- GradientBoosting obtiene el menor error absoluto y el mayor R2.\n",
    "- RandomForest presenta un desempeño cercano, ligeramente inferior.\n",
    "- Los modelos lineales muestran resultados estables pero con mayor error.\n",
    "- La diferencia entre Linear, Ridge y Lasso es marginal, lo que confirma baja multicolinealidad.\n",
    "\n",
    "---\n",
    "\n",
    "### Desempeño Out-of-Time (2026 en adelante)\n",
    "\n",
    "| Modelo                     | MAE    | RMSE   | R2     |\n",
    "|----------------------------|--------|--------|--------|\n",
    "| GradientBoosting           | 278.43 | 350.61 | 0.9250 |\n",
    "| RandomForest               | 288.32 | 363.26 | 0.9195 |\n",
    "| Linear                     | 299.06 | 375.26 | 0.9141 |\n",
    "| Lasso (alpha=0.1)          | 299.05 | 375.25 | 0.9141 |\n",
    "| Ridge (alpha=10)           | 299.05 | 375.25 | 0.9141 |\n",
    "| ElasticNet (a=0.1, l1=0.5) | 302.03 | 379.68 | 0.9121 |\n",
    "\n",
    "**Analisis:**\n",
    "\n",
    "- Se observa una leve degradacion en todos los modelos respecto al Test.\n",
    "- El ranking de desempeño se mantiene estable.\n",
    "- GradientBoosting conserva la mejor capacidad de generalizacion.\n",
    "\n",
    "---\n",
    "\n",
    "### Conclusiones\n",
    "\n",
    "1. Los modelos basados en arboles superan consistentemente a los modelos lineales.\n",
    "2. La degradacion entre Test y OOT es moderada, indicando buena estabilidad temporal.\n",
    "3. Los modelos lineales siguen siendo utiles cuando se prioriza interpretabilidad.\n",
    "4. GradientBoosting presenta el mejor balance entre error y capacidad explicativa."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a18d79c",
   "metadata": {},
   "source": [
    "## 10) Evaluacion mes a mes (backtesting dentro de un rango)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d8f0d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================\n",
    "# 10) EVALUACION MES A MES\n",
    "# ==============================\n",
    "\n",
    "def evaluate_monthly(pipe, data: pd.DataFrame, col_num, target):\n",
    "    \"\"\"\n",
    "    Evalua un modelo (pipe) mes a mes sobre un DataFrame con la columna temporal codmes.\n",
    "\n",
    "    Parametros\n",
    "    ----------\n",
    "    pipe : sklearn Pipeline\n",
    "        Pipeline entrenado (puede incluir scaler + modelo).\n",
    "    data : pd.DataFrame\n",
    "        Dataset a evaluar (por ejemplo: test u oot).\n",
    "    col_num : list\n",
    "        Lista de variables numericas usadas como features.\n",
    "    target : str\n",
    "        Nombre de la variable objetivo.\n",
    "\n",
    "    Retorna\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        Tabla con metricas por mes: MAE, RMSE, R2 y numero de filas.\n",
    "    \"\"\"\n",
    "    out = []\n",
    "\n",
    "    # Recorremos cada mes disponible en orden cronologico\n",
    "    for m in sorted(data[\"codmes\"].unique()):\n",
    "        \n",
    "        # Filtramos el dataset solo para ese mes\n",
    "        df_m = data[data[\"codmes\"] == m]\n",
    "\n",
    "        # Valores reales y predicciones del modelo para ese mes\n",
    "        y_true = df_m[target]\n",
    "        y_pred = pipe.predict(df_m[col_num])\n",
    "\n",
    "        # Metricas de error y ajuste\n",
    "        mae, rmse, r2 = metrics(y_true, y_pred)\n",
    "\n",
    "        # Guardamos resultados\n",
    "        out.append([m, mae, rmse, r2, len(df_m)])\n",
    "\n",
    "    return pd.DataFrame(out, columns=[\"codmes\", \"MAE\", \"RMSE\", \"R2\", \"n_rows\"])\n",
    "\n",
    "\n",
    "# ---------------------------------------\n",
    "# Seleccion del mejor modelo\n",
    "# ---------------------------------------\n",
    "# res ya esta ordenado por MAE_test ascendente, por eso res.iloc[0] es el mejor segun ese criterio.\n",
    "best_name = res.iloc[0][\"modelo\"]\n",
    "best_pipe = fitted[best_name]\n",
    "\n",
    "print(\"Mejor modelo (segun MAE_test):\", best_name)\n",
    "\n",
    "\n",
    "# ---------------------------------------\n",
    "# Evaluacion mensual en Test y OOT\n",
    "# ---------------------------------------\n",
    "# Test: meses del 2025\n",
    "# OOT : meses del 2026 en adelante\n",
    "test_monthly = evaluate_monthly(best_pipe, test, col_num, target)\n",
    "oot_monthly  = evaluate_monthly(best_pipe, oot,  col_num, target)\n",
    "\n",
    "test_monthly.head(), oot_monthly.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1e8cda9",
   "metadata": {},
   "source": [
    "## Evaluacion Mensual - Test (2025) y OOT (2026)\n",
    "\n",
    "### 1. Desempeño Mensual - Test 2025\n",
    "\n",
    "| codmes | MAE      | RMSE     | R2      | Observaciones |\n",
    "|--------|----------|----------|---------|--------------|\n",
    "| 202501 | 273.00   | 347.20   | 0.9297  | Inicio estable del periodo |\n",
    "| 202502 | 268.93   | 335.35   | 0.9296  | Ligera mejora en error |\n",
    "| 202503 | 255.55   | 324.08   | 0.9363  | Mejor mes del periodo |\n",
    "| 202504 | 262.57   | 332.79   | 0.9376  | Alto poder explicativo |\n",
    "| 202505 | 267.85   | 333.54   | 0.9373  | Estabilidad sostenida |\n",
    "\n",
    "**Analisis del periodo Test:**\n",
    "\n",
    "- El MAE se mantiene entre 255 y 273, lo que indica baja volatilidad en el error.\n",
    "- El R2 es consistentemente superior a 0.92, mostrando alta capacidad explicativa.\n",
    "- Marzo (202503) presenta el mejor desempeño del modelo.\n",
    "- No se observan deterioros abruptos ni inestabilidad mensual.\n",
    "\n",
    "---\n",
    "\n",
    "### 2. Desempeño Mensual - OOT 2026\n",
    "\n",
    "| codmes | MAE      | RMSE     | R2      | Observaciones |\n",
    "|--------|----------|----------|---------|--------------|\n",
    "| 202601 | 279.41   | 350.15   | 0.9261  | Ligera degradacion esperada |\n",
    "| 202602 | 277.44   | 351.07   | 0.9239  | Estabilidad en nuevo periodo |\n",
    "\n",
    "**Analisis del periodo OOT:**\n",
    "\n",
    "- Se observa una leve degradacion respecto al Test 2025.\n",
    "- El MAE aumenta aproximadamente 5 a 15 puntos.\n",
    "- El R2 se mantiene por encima de 0.92, indicando buena generalizacion.\n",
    "- No se detecta ruptura estructural fuerte.\n",
    "\n",
    "---\n",
    "\n",
    "### Conclusiones Tecnicas\n",
    "\n",
    "1. El modelo mantiene estabilidad mensual durante 2025.\n",
    "2. La degradacion en 2026 es moderada y esperada en evaluacion out-of-time.\n",
    "3. No se evidencia drift severo.\n",
    "4. El sistema muestra buena capacidad de generalizacion temporal.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d58a6722",
   "metadata": {},
   "source": [
    "## Analisis de Drift Temporal\n",
    "\n",
    "En modelos predictivos con datos cronologicos, el drift se refiere a cambios en la distribucion de los datos o en la relacion entre variables a lo largo del tiempo.\n",
    "\n",
    "Existen tres tipos principales de drift:\n",
    "\n",
    "1. Data Drift: cambio en la distribucion de las variables explicativas.\n",
    "2. Concept Drift: cambio en la relacion entre las variables explicativas y la variable objetivo.\n",
    "3. Prediction Drift: cambio en la distribucion de las predicciones del modelo.\n",
    "\n",
    "En este caso, al comparar el desempeño entre Test (2025) y OOT (2026), se observa:\n",
    "\n",
    "- Un incremento moderado en MAE.\n",
    "- Una ligera disminucion en R2.\n",
    "- Estabilidad general en la estructura del error.\n",
    "\n",
    "Esto sugiere la presencia de drift leve, probablemente asociado a:\n",
    "\n",
    "- Tendencia inflacionaria simulada.\n",
    "- Cambios en el indice de combustible.\n",
    "- Ajustes progresivos en precios promedio.\n",
    "- Variaciones estacionales.\n",
    "\n",
    "Sin embargo, no se observa un deterioro abrupto ni perdida significativa de capacidad explicativa. El modelo mantiene R2 superior a 0.92 incluso en OOT, lo que indica buena generalizacion.\n",
    "\n",
    "Desde una perspectiva productiva, este comportamiento implica:\n",
    "\n",
    "- El modelo es robusto en el corto plazo.\n",
    "- No existe ruptura estructural fuerte.\n",
    "- Se recomienda monitoreo mensual de metricas.\n",
    "- Puede considerarse reentrenamiento periodico si el error comienza a crecer de manera sistematica.\n",
    "\n",
    "En entornos reales, el monitoreo de drift es fundamental para mantener estabilidad y confiabilidad del sistema predictivo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a75613a",
   "metadata": {},
   "source": [
    "### 10.1 Grafico de MAE por mes (validacion 2025)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d949d7e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,4))\n",
    "plt.plot(test_monthly[\"codmes\"], test_monthly[\"MAE\"])\n",
    "plt.xticks(rotation=90)\n",
    "plt.title(f\"MAE por mes (Test 2025) - {best_name}\")\n",
    "plt.xlabel(\"codmes\")\n",
    "plt.ylabel(\"MAE\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(8,3))\n",
    "plt.plot(oot_monthly[\"codmes\"], oot_monthly[\"MAE\"])\n",
    "plt.xticks(rotation=90)\n",
    "plt.title(f\"MAE por mes (OOT 2026+) - {best_name}\")\n",
    "plt.xlabel(\"codmes\")\n",
    "plt.ylabel(\"MAE\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "657f803b",
   "metadata": {},
   "source": [
    "## Analisis Grafico - MAE Mensual GradientBoosting\n",
    "\n",
    "### 1. Test 2025\n",
    "\n",
    "El grafico de MAE mensual durante el periodo Test 2025 muestra una variacion controlada del error.\n",
    "\n",
    "Observaciones principales:\n",
    "\n",
    "- El MAE oscila aproximadamente entre 253 y 282.\n",
    "- El mejor desempeño se observa en septiembre (202509), donde el error es minimo.\n",
    "- Se identifican picos moderados en agosto y hacia finales del año.\n",
    "- No se observa una tendencia creciente sostenida en el error.\n",
    "\n",
    "Interpretacion tecnica:\n",
    "\n",
    "La variacion mensual es esperable en datos reales debido a estacionalidad y cambios en demanda. La ausencia de una tendencia ascendente sistematica indica que el modelo mantiene estabilidad a lo largo del periodo de evaluacion.\n",
    "\n",
    "El comportamiento sugiere que el modelo captura adecuadamente la estructura no lineal del sistema, aunque existen meses con mayor complejidad o volatilidad.\n",
    "\n",
    "---\n",
    "\n",
    "### 2. OOT 2026+\n",
    "\n",
    "En el periodo Out-of-Time (2026 en adelante), el MAE presenta un comportamiento mas estable y ligeramente superior al promedio observado en 2025.\n",
    "\n",
    "Observaciones principales:\n",
    "\n",
    "- El MAE se mantiene en un rango estrecho cercano a 277–279.\n",
    "- Se observa una leve disminucion progresiva del error entre enero y febrero.\n",
    "- No hay evidencia de deterioro abrupto del modelo.\n",
    "\n",
    "Interpretacion tecnica:\n",
    "\n",
    "El mantenimiento de niveles similares de error en OOT indica buena capacidad de generalizacion temporal. \n",
    "\n",
    "Aunque existe una ligera degradacion respecto a algunos meses de 2025, esta es consistente con drift leve y no representa una ruptura estructural.\n",
    "\n",
    "---\n",
    "\n",
    "### 3. Conclusiones del Analisis Grafico\n",
    "\n",
    "1. El modelo muestra estabilidad mensual en Test.\n",
    "2. No se detecta crecimiento exponencial del error.\n",
    "3. El comportamiento en OOT es consistente y controlado.\n",
    "4. La degradacion es leve y esperada en escenarios temporales.\n",
    "\n",
    "En conjunto, el GradientBoosting demuestra robustez frente a cambios temporales y mantiene capacidad predictiva elevada en escenarios fuera de muestra."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c63c78c",
   "metadata": {},
   "source": [
    "## 11) Cross-Validation temporal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47ee4144",
   "metadata": {},
   "source": [
    "### 11.1 TimeSeriesSplit (por filas ordenadas en el tiempo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed653deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================\n",
    "# 11.1 CROSS-VALIDATION TEMPORAL (TimeSeriesSplit)\n",
    "# ==============================\n",
    "\n",
    "def temporal_cv_mae(model, X, y, n_splits=5, linear=False):\n",
    "    \"\"\"\n",
    "    Calcula MAE promedio usando TimeSeriesSplit (validacion cruzada temporal).\n",
    "\n",
    "    TimeSeriesSplit respeta el orden cronologico:\n",
    "    - Entrena con un bloque historico\n",
    "    - Valida en un bloque posterior\n",
    "    - En cada fold el train se expande (expanding window)\n",
    "\n",
    "    Parametros\n",
    "    ----------\n",
    "    model : sklearn estimator\n",
    "        Modelo base (Linear, Ridge, RF, GB, etc.)\n",
    "    X : pd.DataFrame\n",
    "        Features del conjunto de entrenamiento (ordenadas cronologicamente).\n",
    "    y : pd.Series\n",
    "        Target del conjunto de entrenamiento (mismo orden que X).\n",
    "    n_splits : int\n",
    "        Numero de folds temporales.\n",
    "    linear : bool\n",
    "        Si True, aplica StandardScaler antes del modelo (recomendado para modelos lineales).\n",
    "\n",
    "    Retorna\n",
    "    -------\n",
    "    float\n",
    "        MAE promedio en los folds temporales.\n",
    "    \"\"\"\n",
    "    tscv = TimeSeriesSplit(n_splits=n_splits)\n",
    "\n",
    "    maes = []\n",
    "\n",
    "    # split(X) entrega indices para train/test respetando el tiempo\n",
    "    for fold, (tr_idx, te_idx) in enumerate(tscv.split(X), start=1):\n",
    "        X_tr, X_te = X.iloc[tr_idx], X.iloc[te_idx]\n",
    "        y_tr, y_te = y.iloc[tr_idx], y.iloc[te_idx]\n",
    "\n",
    "        # Modelos lineales requieren estandarizacion para comparabilidad de escala\n",
    "        if linear:\n",
    "            pipe = Pipeline([\n",
    "                (\"scaler\", StandardScaler()),\n",
    "                (\"model\", model)\n",
    "            ])\n",
    "        else:\n",
    "            pipe = Pipeline([\n",
    "                (\"model\", model)\n",
    "            ])\n",
    "\n",
    "        # Entrenar en train (historico)\n",
    "        pipe.fit(X_tr, y_tr)\n",
    "\n",
    "        # Predecir en el bloque temporal posterior\n",
    "        pred = pipe.predict(X_te)\n",
    "\n",
    "        # MAE por fold\n",
    "        mae_fold = mean_absolute_error(y_te, pred)\n",
    "        maes.append(mae_fold)\n",
    "\n",
    "    # MAE promedio sobre los folds\n",
    "    return float(np.mean(maes))\n",
    "\n",
    "\n",
    "# ---------------------------------------\n",
    "# Ejecutar CV temporal para todos los modelos\n",
    "# ---------------------------------------\n",
    "cv_rows = []\n",
    "\n",
    "for name, model in models.items():\n",
    "    cv_mae = temporal_cv_mae(\n",
    "        model=model,\n",
    "        X=X_train,\n",
    "        y=y_train,\n",
    "        n_splits=5,\n",
    "        linear=(name in linear_names)\n",
    "    )\n",
    "    cv_rows.append([name, cv_mae])\n",
    "\n",
    "# Tabla final ordenada por menor MAE (mejor)\n",
    "cv_df = pd.DataFrame(cv_rows, columns=[\"modelo\", \"MAE_cv_TSS\"]).sort_values(\"MAE_cv_TSS\")\n",
    "cv_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b1a5722",
   "metadata": {},
   "source": [
    "## Que es TSS (TimeSeriesSplit)\n",
    "\n",
    "TSS significa TimeSeriesSplit. Es una tecnica de validacion cruzada diseñada especificamente para datos con estructura temporal.\n",
    "\n",
    "En problemas tradicionales de machine learning, es comun usar K-Fold Cross-Validation, donde los datos se mezclan aleatoriamente antes de dividirse en folds. Sin embargo, en datos temporales esto es incorrecto, ya que rompe el orden cronologico y puede generar leakage (usar informacion del futuro para predecir el pasado).\n",
    "\n",
    "TimeSeriesSplit resuelve este problema manteniendo el orden temporal.\n",
    "\n",
    "### Como funciona\n",
    "\n",
    "En cada iteracion:\n",
    "\n",
    "1. Se entrena el modelo usando datos historicos.\n",
    "2. Se valida utilizando datos posteriores en el tiempo.\n",
    "3. En la siguiente iteracion, el conjunto de entrenamiento se expande.\n",
    "\n",
    "Ejemplo conceptual:\n",
    "\n",
    "Fold 1:\n",
    "Train: 2022  \n",
    "Test: 2023  \n",
    "\n",
    "Fold 2:\n",
    "Train: 2022-2023  \n",
    "Test: 2024  \n",
    "\n",
    "Fold 3:\n",
    "Train: 2022-2024  \n",
    "Test: 2025  \n",
    "\n",
    "Este esquema simula el comportamiento real de produccion, donde siempre se entrena con informacion pasada y se predice el futuro.\n",
    "\n",
    "### Por que es importante\n",
    "\n",
    "- Evita leakage temporal.\n",
    "- Simula condiciones reales de despliegue.\n",
    "- Permite evaluar estabilidad en el tiempo.\n",
    "- Es fundamental cuando existe tendencia, estacionalidad o drift.\n",
    "\n",
    "En resumen, TSS es la version correcta de cross-validation cuando los datos tienen componente temporal."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19ecd9b0",
   "metadata": {},
   "source": [
    "## Cross-Validation Temporal (TimeSeriesSplit)\n",
    "\n",
    "La tabla presenta el MAE promedio obtenido mediante validacion cruzada temporal utilizando TimeSeriesSplit sobre el conjunto de entrenamiento.\n",
    "\n",
    "### Resultados\n",
    "\n",
    "| Modelo                     | MAE_cv_TSS |\n",
    "|----------------------------|------------|\n",
    "| GradientBoosting           | 274.57     |\n",
    "| RandomForest               | 284.93     |\n",
    "| Linear                     | 293.20     |\n",
    "| Lasso (alpha=0.1)          | 293.20     |\n",
    "| Ridge (alpha=10)           | 293.26     |\n",
    "| ElasticNet (a=0.1, l1=0.5) | 298.75     |\n",
    "\n",
    "### Analisis\n",
    "\n",
    "- GradientBoosting obtiene el menor MAE promedio en validacion temporal.\n",
    "- RandomForest muestra un desempeño competitivo pero inferior.\n",
    "- Los modelos lineales presentan errores mayores y practicamente equivalentes entre si.\n",
    "- ElasticNet es el modelo con peor desempeño en este esquema de validacion.\n",
    "\n",
    "### Interpretacion Tecnica\n",
    "\n",
    "El uso de TimeSeriesSplit permite evaluar el modelo respetando el orden cronologico, evitando leakage temporal.\n",
    "\n",
    "Los resultados confirman lo observado en Test y OOT:\n",
    "\n",
    "1. Los modelos basados en arboles capturan mejor la dinamica temporal.\n",
    "2. La regularizacion no mejora significativamente el modelo lineal en este dataset.\n",
    "3. La diferencia entre Ridge, Lasso y Linear es marginal, lo que sugiere estabilidad estructural en las variables.\n",
    "\n",
    "### Conclusion\n",
    "\n",
    "GradientBoosting no solo lidera en Test y OOT, sino tambien en validacion cruzada temporal, lo que refuerza su consistencia y robustez ante diferentes esquemas de evaluacion.\n",
    "\n",
    "Este resultado sugiere que el modelo tiene buena capacidad de generalizacion y estabilidad en distintos cortes temporales."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36061415",
   "metadata": {},
   "source": [
    "### 11.2 CV por bloques mensuales (mas parecido a industria)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a84f0ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================\n",
    "# 11.2 Month-block CV\n",
    "# ==============================\n",
    "def month_block_cv(data, model, col_num, target, months_per_fold=3, linear=False):\n",
    "    months = sorted(data[\"codmes\"].unique())\n",
    "    maes = []\n",
    "    \n",
    "    for i in range(months_per_fold, len(months), months_per_fold):\n",
    "        test_months = months[i:i+months_per_fold]\n",
    "        train_months = months[:i]\n",
    "        if len(test_months) == 0:\n",
    "            continue\n",
    "        \n",
    "        tr = data[data[\"codmes\"].isin(train_months)]\n",
    "        te = data[data[\"codmes\"].isin(test_months)]\n",
    "        \n",
    "        X_tr, y_tr = tr[col_num], tr[target]\n",
    "        X_te, y_te = te[col_num], te[target]\n",
    "        \n",
    "        if linear:\n",
    "            pipe = Pipeline([(\"scaler\", StandardScaler()), (\"model\", model)])\n",
    "        else:\n",
    "            pipe = Pipeline([(\"model\", model)])\n",
    "        \n",
    "        pipe.fit(X_tr, y_tr)\n",
    "        pred = pipe.predict(X_te)\n",
    "        maes.append(mean_absolute_error(y_te, pred))\n",
    "    \n",
    "    return float(np.mean(maes))\n",
    "\n",
    "cv2_rows = []\n",
    "for name, model in models.items():\n",
    "    cv_mae = month_block_cv(train, model, col_num, target, months_per_fold=3, linear=(name in linear_names))\n",
    "    cv2_rows.append([name, cv_mae])\n",
    "\n",
    "month_cv = pd.DataFrame(cv2_rows, columns=[\"modelo\",\"MAE_cv_monthblocks\"]).sort_values(\"MAE_cv_monthblocks\")\n",
    "month_cv\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6ad60e1",
   "metadata": {},
   "source": [
    "## Cross-Validation por Bloques Mensuales\n",
    "\n",
    "En este esquema de validacion, los datos se dividen en bloques completos de meses consecutivos. \n",
    "Cada iteracion entrena con meses anteriores y evalua sobre un bloque posterior fijo, manteniendo la estructura temporal.\n",
    "\n",
    "### Resultados\n",
    "\n",
    "| Modelo                     | MAE_cv_monthblocks |\n",
    "|----------------------------|-------------------|\n",
    "| GradientBoosting           | 274.79            |\n",
    "| RandomForest               | 284.35            |\n",
    "| Linear                     | 293.32            |\n",
    "| Lasso (alpha=0.1)          | 293.32            |\n",
    "| Ridge (alpha=10)           | 293.36            |\n",
    "| ElasticNet (a=0.1, l1=0.5) | 298.73            |\n",
    "\n",
    "### Analisis\n",
    "\n",
    "- GradientBoosting mantiene el menor error promedio.\n",
    "- RandomForest conserva un desempeño competitivo.\n",
    "- Los modelos lineales presentan errores practicamente identicos entre si.\n",
    "- ElasticNet muestra el mayor MAE dentro del conjunto evaluado.\n",
    "\n",
    "### Interpretacion Tecnica\n",
    "\n",
    "La validacion por bloques mensuales es mas estricta que TimeSeriesSplit tradicional, ya que:\n",
    "\n",
    "- Evalua el modelo en periodos completos.\n",
    "- Evita fragmentar meses entre train y test.\n",
    "- Se acerca mas a un escenario real de backtesting.\n",
    "\n",
    "Los resultados son consistentes con:\n",
    "\n",
    "- Evaluacion en Test.\n",
    "- Evaluacion Out-of-Time.\n",
    "- TimeSeriesSplit.\n",
    "\n",
    "Esta consistencia entre distintos esquemas de validacion refuerza la estabilidad del ranking de modelos y la robustez del enfoque basado en arboles.\n",
    "\n",
    "### Conclusión\n",
    "\n",
    "GradientBoosting demuestra superioridad sostenida bajo multiples esquemas de validacion temporal, lo que respalda su seleccion como modelo principal."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8e458db",
   "metadata": {},
   "source": [
    "## 12) Rolling Window Backtest (ventana movil)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13c95042",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================\n",
    "# 12) Rolling Window\n",
    "# ==============================\n",
    "def rolling_window_backtest(data, model, col_num, target, train_window=12, test_window=1, linear=False):\n",
    "    months = sorted(data[\"codmes\"].unique())\n",
    "    out = []\n",
    "    \n",
    "    for start in range(0, len(months) - train_window - test_window + 1):\n",
    "        tr_months = months[start:start+train_window]\n",
    "        te_months = months[start+train_window:start+train_window+test_window]\n",
    "        \n",
    "        tr = data[data[\"codmes\"].isin(tr_months)]\n",
    "        te = data[data[\"codmes\"].isin(te_months)]\n",
    "        \n",
    "        X_tr, y_tr = tr[col_num], tr[target]\n",
    "        X_te, y_te = te[col_num], te[target]\n",
    "        \n",
    "        if linear:\n",
    "            pipe = Pipeline([(\"scaler\", StandardScaler()), (\"model\", model)])\n",
    "        else:\n",
    "            pipe = Pipeline([(\"model\", model)])\n",
    "        \n",
    "        pipe.fit(X_tr, y_tr)\n",
    "        pred = pipe.predict(X_te)\n",
    "        \n",
    "        mae, rmse, r2 = metrics(y_te, pred)\n",
    "        out.append([te_months[-1], mae, rmse, r2, len(tr_months)])\n",
    "    \n",
    "    return pd.DataFrame(out, columns=[\"codmes\",\"MAE\",\"RMSE\",\"R2\",\"train_window_months\"])\n",
    "\n",
    "train_val = df[df[\"codmes\"] <= 202512].copy()\n",
    "\n",
    "rw_ridge = rolling_window_backtest(train_val, Ridge(alpha=10), col_num, target, train_window=12, test_window=1, linear=True)\n",
    "rw_rf    = rolling_window_backtest(train_val, RandomForestRegressor(n_estimators=350, random_state=42, n_jobs=-1),\n",
    "                                   col_num, target, train_window=12, test_window=1, linear=False)\n",
    "\n",
    "rw_ridge.head(), rw_rf.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39b9f7fd",
   "metadata": {},
   "source": [
    "## Rolling Window Backtest (Ventana de 12 Meses)\n",
    "\n",
    "En este esquema, el modelo se entrena utilizando una ventana fija de 12 meses y se evalua sobre el mes siguiente. \n",
    "Este enfoque permite analizar la estabilidad del modelo cuando solo se dispone de informacion reciente.\n",
    "\n",
    "### Resultados - Modelo Lineal (Ridge)\n",
    "\n",
    "| codmes | MAE    | RMSE   | R2     | Meses en Train |\n",
    "|--------|--------|--------|--------|----------------|\n",
    "| 202301 | 289.22 | 361.55 | 0.9188 | 12             |\n",
    "| 202302 | 304.40 | 381.48 | 0.9184 | 12             |\n",
    "| 202303 | 284.46 | 352.58 | 0.9310 | 12             |\n",
    "| 202304 | 295.49 | 377.71 | 0.9034 | 12             |\n",
    "| 202305 | 294.71 | 368.27 | 0.9140 | 12             |\n",
    "\n",
    "### Resultados - RandomForest\n",
    "\n",
    "| codmes | MAE    | RMSE   | R2     | Meses en Train |\n",
    "|--------|--------|--------|--------|----------------|\n",
    "| 202301 | 269.85 | 337.78 | 0.9292 | 12             |\n",
    "| 202302 | 286.82 | 355.73 | 0.9290 | 12             |\n",
    "| 202303 | 274.58 | 342.78 | 0.9348 | 12             |\n",
    "| 202304 | 290.40 | 365.59 | 0.9095 | 12             |\n",
    "| 202305 | 288.79 | 361.23 | 0.9172 | 12             |\n",
    "\n",
    "### Analisis Comparativo\n",
    "\n",
    "1. RandomForest mantiene menor MAE en todos los meses observados.\n",
    "2. El modelo lineal presenta mayor variabilidad en el error.\n",
    "3. Ambos modelos muestran fluctuaciones mensuales, lo cual es esperado en entornos temporales.\n",
    "4. El R2 se mantiene por encima de 0.90 en todos los casos, indicando buena capacidad explicativa aun con ventana limitada.\n",
    "\n",
    "### Interpretacion Tecnica\n",
    "\n",
    "El Rolling Window es mas exigente que entrenar con todo el historico, ya que el modelo solo utiliza informacion reciente (12 meses).\n",
    "\n",
    "Este esquema permite evaluar:\n",
    "\n",
    "- Sensibilidad del modelo a cambios estructurales.\n",
    "- Impacto de usar memoria corta en lugar de historico completo.\n",
    "- Robustez ante drift temporal.\n",
    "\n",
    "Los resultados muestran que el modelo basado en arboles mantiene mejor estabilidad bajo restricciones de ventana, lo que sugiere mayor capacidad para capturar patrones no lineales en contextos dinamicos.\n",
    "\n",
    "### Conclusion\n",
    "\n",
    "Bajo un escenario de ventana fija de 12 meses:\n",
    "\n",
    "- RandomForest demuestra mayor estabilidad.\n",
    "- El modelo lineal mantiene desempeño razonable pero con mayor variabilidad.\n",
    "- No se observa deterioro sistematico, lo que indica ausencia de drift severo en el periodo evaluado."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b8fb510",
   "metadata": {},
   "source": [
    "### 12.1 Grafico: rolling MAE (Ridge vs RandomForest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e39489a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,4))\n",
    "plt.plot(rw_ridge[\"codmes\"], rw_ridge[\"MAE\"], label=\"Ridge (12m)\")\n",
    "plt.plot(rw_rf[\"codmes\"], rw_rf[\"MAE\"], label=\"RandomForest (12m)\")\n",
    "plt.xticks(rotation=90)\n",
    "plt.title(\"Rolling Window Backtest: MAE (12 meses train, 1 mes test)\")\n",
    "plt.xlabel(\"codmes\")\n",
    "plt.ylabel(\"MAE\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9e630eb",
   "metadata": {},
   "source": [
    "## 13) Feature Importance comparada"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "717c3d0a",
   "metadata": {},
   "source": [
    "### 13.1 Coeficientes (Ridge) en escala estandarizada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12c63269",
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge_pipe = Pipeline([(\"scaler\", StandardScaler()), (\"model\", Ridge(alpha=10))])\n",
    "ridge_pipe.fit(X_train, y_train)\n",
    "\n",
    "coef = ridge_pipe.named_steps[\"model\"].coef_\n",
    "coef_df = pd.DataFrame({\"feature\": col_num, \"coef_std\": coef}).sort_values(\"coef_std\", key=np.abs, ascending=False)\n",
    "coef_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0d131d7",
   "metadata": {},
   "source": [
    "## Interpretacion de Coeficientes Estandarizados (Ridge)\n",
    "\n",
    "Los coeficientes presentados corresponden a un modelo Ridge entrenado con variables estandarizadas (z-score). \n",
    "\n",
    "Esto implica que cada coeficiente representa el impacto esperado en la variable objetivo ante un aumento de una desviacion estandar en la variable explicativa, manteniendo las demas constantes.\n",
    "\n",
    "### Resultados\n",
    "\n",
    "| Variable                  | Coeficiente Estandarizado |\n",
    "|---------------------------|---------------------------|\n",
    "| viajes_realizados         | 1035.16                   |\n",
    "| precio_promedio_viaje     | 731.19                    |\n",
    "| incentivo_bono            | 105.26                    |\n",
    "| cancelaciones_pct         | -31.12                    |\n",
    "| rating_promedio           | 29.15                     |\n",
    "| horas_conectado           | 20.73                     |\n",
    "| combustible_indice        | -12.80                    |\n",
    "| antiguedad_meses          | 3.60                      |\n",
    "\n",
    "### Analisis\n",
    "\n",
    "1. viajes_realizados es la variable con mayor impacto en el ingreso mensual. Esto es consistente con la logica del negocio: mas viajes implican mayor facturacion.\n",
    "   \n",
    "2. precio_promedio_viaje es el segundo factor mas relevante. Cambios en la tarifa promedio afectan directamente el ingreso total.\n",
    "\n",
    "3. incentivo_bono tiene impacto positivo significativo, aunque menor que los drivers principales.\n",
    "\n",
    "4. cancelaciones_pct tiene coeficiente negativo, indicando que mayores cancelaciones reducen el ingreso neto.\n",
    "\n",
    "5. combustible_indice presenta efecto negativo, reflejando el impacto de costos operativos.\n",
    "\n",
    "6. antiguedad_meses tiene efecto marginal, lo que sugiere que la experiencia no es un driver dominante en este esquema.\n",
    "\n",
    "### Interpretacion Economica\n",
    "\n",
    "El modelo confirma que el ingreso esta principalmente determinado por volumen (viajes) y precio (ticket promedio), mientras que factores operativos y de eficiencia tienen impacto secundario.\n",
    "\n",
    "El signo y magnitud de los coeficientes son coherentes con la estructura generadora del dataset.\n",
    "\n",
    "### Conclusion\n",
    "\n",
    "El modelo lineal ofrece interpretabilidad clara y consistente con la logica del negocio, aunque en terminos de precision predictiva fue superado por modelos no lineales."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6ed37f4",
   "metadata": {},
   "source": [
    "### 13.2 Permutation Importance (RandomForest) usando validacion 2025"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0bc3f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestRegressor(n_estimators=350, random_state=42, n_jobs=-1)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "perm = permutation_importance(rf, X_test, y_test, n_repeats=10, random_state=42, n_jobs=-1)\n",
    "perm_df = pd.DataFrame({\"feature\": col_num, \"perm_importance\": perm.importances_mean}).sort_values(\"perm_importance\", ascending=False)\n",
    "perm_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c429e2da",
   "metadata": {},
   "source": [
    "## Permutation Importance - RandomForest\n",
    "\n",
    "La importancia por permutacion mide la variacion en el error del modelo cuando se altera aleatoriamente una variable. \n",
    "\n",
    "Si al permutar una variable el error aumenta significativamente, significa que el modelo depende fuertemente de esa variable para realizar buenas predicciones.\n",
    "\n",
    "### Resultados\n",
    "\n",
    "| Variable              | Permutation Importance |\n",
    "|-----------------------|------------------------|\n",
    "| viajes_realizados     | 1.2568                 |\n",
    "| precio_promedio_viaje | 0.6170                 |\n",
    "| incentivo_bono        | 0.0076                 |\n",
    "| cancelaciones_pct     | 0.0009                 |\n",
    "| rating_promedio       | 0.0005                 |\n",
    "| horas_conectado       | 0.0004                 |\n",
    "| combustible_indice    | 0.0001                 |\n",
    "| antiguedad_meses      | 0.0001                 |\n",
    "\n",
    "### Analisis\n",
    "\n",
    "1. viajes_realizados es claramente la variable mas influyente. Al alterar su informacion, el error aumenta de forma significativa.\n",
    "\n",
    "2. precio_promedio_viaje es el segundo factor mas relevante, aunque con impacto menor que el volumen de viajes.\n",
    "\n",
    "3. El resto de variables presentan importancia marginal bajo este modelo.\n",
    "\n",
    "### Interpretacion Tecnica\n",
    "\n",
    "En modelos basados en arboles, la Permutation Importance refleja la contribucion real de cada variable al poder predictivo, considerando interacciones y no linealidades.\n",
    "\n",
    "La gran diferencia entre las dos primeras variables y el resto indica que el sistema esta principalmente explicado por:\n",
    "\n",
    "- Volumen de actividad.\n",
    "- Precio promedio por transaccion.\n",
    "\n",
    "Las demas variables aportan ajustes finos pero no determinan el comportamiento global del ingreso.\n",
    "\n",
    "### Comparacion con Modelo Lineal\n",
    "\n",
    "La jerarquia observada es consistente con los coeficientes del modelo Ridge:\n",
    "\n",
    "- viajes_realizados y precio_promedio_viaje lideran en ambos enfoques.\n",
    "- Variables operativas tienen impacto secundario.\n",
    "\n",
    "Esto refuerza la coherencia estructural del dataset y la estabilidad de los resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85f9b14f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import plot_tree\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "gb = fitted[\"GradientBoosting\"].named_steps[\"model\"]\n",
    "\n",
    "plt.figure(figsize=(14,6))\n",
    "plot_tree(gb.estimators_[0,0],\n",
    "          feature_names=col_num,\n",
    "          filled=True,\n",
    "          max_depth=3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4baa253d",
   "metadata": {},
   "source": [
    "## 14) SHAP (interpretabilidad para modelos no lineales)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13fb8ab6",
   "metadata": {},
   "source": [
    "> Nota: si SHAP no esta instalado, instala con `pip install shap` y reinicia el kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d20416b",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import shap\n",
    "    import numpy as np\n",
    "\n",
    "    # Usa el modelo ya entrenado si lo tienes (mejor)\n",
    "    # Si no, entrena rápido uno\n",
    "    rf = RandomForestRegressor(n_estimators=350, random_state=42, n_jobs=-1)\n",
    "    rf.fit(X_train, y_train)\n",
    "\n",
    "    # 1) MUY IMPORTANTE: reducir muestra\n",
    "    # 200-500 filas suele ser ideal para clase\n",
    "    n_explain = min(400, len(X_test))\n",
    "    sample = X_test.sample(n_explain, random_state=42)\n",
    "\n",
    "    # 2) Background pequeno para acelerar (opcional pero recomendado)\n",
    "    background = X_train.sample(min(100, len(X_train)), random_state=42)\n",
    "\n",
    "    # 3) TreeExplainer con background\n",
    "    explainer = shap.TreeExplainer(rf, data=background)\n",
    "    shap_values = explainer.shap_values(sample)\n",
    "\n",
    "    # 4) Primero solo BAR (mas rapido y suficiente para clase)\n",
    "    shap.summary_plot(shap_values, sample, plot_type=\"bar\", show=True)\n",
    "\n",
    "    # 5) Scatter opcional (pesado). Activalo solo si quieres.\n",
    "    # shap.summary_plot(shap_values, sample, show=True)\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"SHAP no disponible o error al ejecutar SHAP. Detalle:\", repr(e))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46111641",
   "metadata": {},
   "source": [
    "## 15) Reentrenamiento automatico mensual (Walk-Forward) + evaluacion mes a mes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2a45fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================\n",
    "# 15) Walk-Forward (robusto, con minimo de meses)\n",
    "# ==============================\n",
    "def walk_forward_retrain(\n",
    "    data,\n",
    "    model,\n",
    "    col_num,\n",
    "    target,\n",
    "    start_month,\n",
    "    end_month,\n",
    "    linear=False,\n",
    "    min_train_months=6  # minimo 6 meses de historia antes de entrenar\n",
    "):\n",
    "    months_all = sorted(data[\"codmes\"].unique())\n",
    "    months = [m for m in months_all if start_month <= m <= end_month]\n",
    "\n",
    "    out = []\n",
    "\n",
    "    for m in months:\n",
    "        tr = data[data[\"codmes\"] < m]\n",
    "        te = data[data[\"codmes\"] == m]\n",
    "\n",
    "        # contar cuantos meses de historia real hay antes del mes m\n",
    "        n_months_hist = tr[\"codmes\"].nunique()\n",
    "\n",
    "        # si no hay suficiente historia, saltar este mes\n",
    "        if n_months_hist < min_train_months:\n",
    "            continue\n",
    "\n",
    "        X_tr, y_tr = tr[col_num], tr[target]\n",
    "        X_te, y_te = te[col_num], te[target]\n",
    "\n",
    "        if linear:\n",
    "            pipe = Pipeline([(\"scaler\", StandardScaler()), (\"model\", model)])\n",
    "        else:\n",
    "            pipe = Pipeline([(\"model\", model)])\n",
    "\n",
    "        pipe.fit(X_tr, y_tr)\n",
    "        pred = pipe.predict(X_te)\n",
    "\n",
    "        mae, rmse, r2 = metrics(y_te, pred)\n",
    "        out.append([m, mae, rmse, r2, len(tr), len(te), n_months_hist])\n",
    "\n",
    "    return pd.DataFrame(\n",
    "        out,\n",
    "        columns=[\"codmes\", \"MAE\", \"RMSE\", \"R2\", \"n_train_rows\", \"n_test_rows\", \"n_train_months\"]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "421e54a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "wf_back_ridge = walk_forward_retrain(df, Ridge(alpha=10), col_num, target, 202201, 202212, linear=True,  min_train_months=6)\n",
    "wf_test_ridge = walk_forward_retrain(df, Ridge(alpha=10), col_num, target, 202501, 202512, linear=True,  min_train_months=6)\n",
    "wf_test_rf    = walk_forward_retrain(df, RandomForestRegressor(n_estimators=350, random_state=42, n_jobs=-1),\n",
    "                                     col_num, target, 202501, 202512, linear=False, min_train_months=6)\n",
    "wf_oot_rf     = walk_forward_retrain(df, RandomForestRegressor(n_estimators=350, random_state=42, n_jobs=-1),\n",
    "                                     col_num, target, 202601, int(df[\"codmes\"].max()), linear=False, min_train_months=6)\n",
    "\n",
    "wf_back_ridge.head(), wf_test_ridge.head(), wf_oot_rf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b4365bd",
   "metadata": {},
   "source": [
    "## Walk-Forward Expandido (Reentrenamiento Acumulativo)\n",
    "\n",
    "En este esquema, el modelo se reentrena cada mes utilizando toda la informacion historica disponible hasta el periodo anterior. \n",
    "\n",
    "A diferencia del Rolling Window con ventana fija, aqui la cantidad de datos de entrenamiento crece progresivamente.\n",
    "\n",
    "---\n",
    "\n",
    "### 1. Backtesting 2022 (Historial Minimo)\n",
    "\n",
    "| codmes | MAE    | RMSE   | R2     | Meses en Train |\n",
    "|--------|--------|--------|--------|----------------|\n",
    "| 202207 | 302.49 | 385.52 | 0.9140 | 6              |\n",
    "| 202208 | 285.88 | 357.49 | 0.9182 | 7              |\n",
    "| 202209 | 282.51 | 360.18 | 0.9224 | 8              |\n",
    "| 202210 | 284.63 | 356.99 | 0.9212 | 9              |\n",
    "| 202211 | 292.70 | 361.85 | 0.9222 | 10             |\n",
    "\n",
    "**Analisis:**\n",
    "\n",
    "- El error disminuye a medida que aumenta la historia disponible.\n",
    "- El R2 mejora conforme el modelo incorpora mas informacion.\n",
    "- Esto evidencia que el modelo se beneficia de mayor volumen historico.\n",
    "\n",
    "---\n",
    "\n",
    "### 2. Test 2025 (Historial Consolidado)\n",
    "\n",
    "| codmes | MAE    | RMSE   | R2     | Meses en Train |\n",
    "|--------|--------|--------|--------|----------------|\n",
    "| 202501 | 282.73 | 357.09 | 0.9256 | 36             |\n",
    "| 202502 | 297.25 | 369.81 | 0.9144 | 37             |\n",
    "| 202503 | 275.06 | 351.32 | 0.9252 | 38             |\n",
    "| 202504 | 287.73 | 365.01 | 0.9249 | 39             |\n",
    "| 202505 | 291.79 | 367.82 | 0.9238 | 40             |\n",
    "\n",
    "**Analisis:**\n",
    "\n",
    "- El modelo muestra estabilidad con historial amplio.\n",
    "- El MAE fluctua dentro de un rango controlado.\n",
    "- No se observa deterioro progresivo.\n",
    "\n",
    "---\n",
    "\n",
    "### 3. OOT 2026 (Escenario Futuro)\n",
    "\n",
    "| codmes | MAE    | RMSE   | R2     | Meses en Train |\n",
    "|--------|--------|--------|--------|----------------|\n",
    "| 202601 | 281.72 | 357.13 | 0.9231 | 48             |\n",
    "| 202602 | 284.17 | 358.51 | 0.9207 | 49             |\n",
    "\n",
    "**Analisis:**\n",
    "\n",
    "- El desempeño se mantiene consistente en periodo fuera de muestra.\n",
    "- La leve variacion es esperable por drift temporal.\n",
    "- El R2 permanece por encima de 0.92, indicando buena generalizacion.\n",
    "\n",
    "---\n",
    "\n",
    "### Interpretacion Global\n",
    "\n",
    "1. A mayor cantidad de historia disponible, el modelo tiende a estabilizar el error.\n",
    "2. No se evidencia deterioro estructural fuerte.\n",
    "3. El comportamiento en OOT confirma robustez temporal.\n",
    "4. El reentrenamiento acumulativo es una estrategia adecuada en escenarios con drift moderado.\n",
    "\n",
    "---\n",
    "\n",
    "### Conclusión\n",
    "\n",
    "El walk-forward expandido demuestra que el modelo mantiene consistencia cuando se actualiza periodicamente con informacion nueva. \n",
    "\n",
    "Este esquema reproduce fielmente un entorno productivo donde el modelo se recalibra de forma continua para preservar estabilidad predictiva."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02c6d7be",
   "metadata": {},
   "source": [
    "### 15.1 Grafico: Walk-forward MAE 2025 (Ridge vs RF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5c0ec84",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,4))\n",
    "plt.plot(wf_test_ridge[\"codmes\"], wf_test_ridge[\"MAE\"], marker=\"o\", label=\"Ridge\")\n",
    "plt.plot(wf_test_rf[\"codmes\"], wf_test_rf[\"MAE\"], marker=\"o\", label=\"RandomForest\")\n",
    "plt.xticks(rotation=90)\n",
    "plt.title(\"Walk-forward - MAE Test 2025 (min 6 meses historia)\")\n",
    "plt.xlabel(\"codmes\")\n",
    "plt.ylabel(\"MAE\")\n",
    "plt.legend()\n",
    "plt.grid(alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.figure(figsize=(8,3))\n",
    "plt.plot(wf_oot_rf[\"codmes\"], wf_oot_rf[\"MAE\"], marker=\"o\", label=\"RandomForest OOT\")\n",
    "plt.xticks(rotation=90)\n",
    "plt.title(\"Walk-forward - MAE OOT 2026+ (min 6 meses historia)\")\n",
    "plt.xlabel(\"codmes\")\n",
    "plt.ylabel(\"MAE\")\n",
    "plt.legend()\n",
    "plt.grid(alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1c2a474",
   "metadata": {},
   "source": [
    "## Analisis Grafico - Walk-Forward con Minimo 6 Meses de Historia\n",
    "\n",
    "### 1. Walk-Forward - Test 2025\n",
    "\n",
    "El grafico muestra la evolucion mensual del MAE bajo un esquema de reentrenamiento acumulativo, utilizando un minimo de 6 meses de historia.\n",
    "\n",
    "Observaciones principales:\n",
    "\n",
    "- RandomForest mantiene menor MAE que Ridge en todos los meses.\n",
    "- Ridge presenta mayor variabilidad y un incremento marcado hacia finales del periodo.\n",
    "- RandomForest muestra comportamiento mas estable.\n",
    "- Ambos modelos presentan fluctuaciones normales asociadas a variaciones mensuales.\n",
    "\n",
    "Interpretacion tecnica:\n",
    "\n",
    "El modelo basado en arboles captura mejor las no linealidades y las interacciones entre variables, lo que reduce la sensibilidad a cambios mensuales.\n",
    "\n",
    "La mayor volatilidad observada en Ridge sugiere que los modelos lineales son mas sensibles a cambios en la distribucion o en la relacion entre variables.\n",
    "\n",
    "---\n",
    "\n",
    "### 2. Walk-Forward - OOT 2026+\n",
    "\n",
    "En el periodo Out-of-Time, el MAE del modelo RandomForest se mantiene dentro de un rango estrecho.\n",
    "\n",
    "Observaciones principales:\n",
    "\n",
    "- El error se mantiene estable entre aproximadamente 281 y 284.\n",
    "- No se observa deterioro abrupto.\n",
    "- La variacion mensual es limitada.\n",
    "\n",
    "Interpretacion tecnica:\n",
    "\n",
    "El comportamiento estable en OOT indica buena capacidad de generalizacion. \n",
    "El modelo mantiene consistencia incluso cuando se proyecta a periodos completamente fuera del rango de entrenamiento original.\n",
    "\n",
    "---\n",
    "\n",
    "### Conclusion del Walk-Forward\n",
    "\n",
    "1. El reentrenamiento acumulativo estabiliza el error a medida que aumenta la historia disponible.\n",
    "2. RandomForest muestra mayor robustez que Ridge bajo esquema dinamico.\n",
    "3. No se detecta drift severo en el periodo analizado.\n",
    "4. El modelo es adecuado para un esquema de actualizacion mensual en produccion.\n",
    "\n",
    "Este analisis confirma que el modelo seleccionado no solo es preciso en evaluacion estatica, sino tambien estable en un entorno de actualizacion continua."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8233b31a",
   "metadata": {},
   "source": [
    "## 16) Ecuacion final (modelo lineal)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02bd0f95",
   "metadata": {},
   "source": [
    "Aqui mostramos la ecuacion del **Ridge** entrenado sobre `train + val` (hasta 202512). Los coeficientes estan sobre variables estandarizadas (z-score)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6994f0a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_hist = df[df[\"codmes\"] <= 202512].copy()\n",
    "X_hist, y_hist = train_hist[col_num], train_hist[target]\n",
    "\n",
    "final_ridge = Pipeline([(\"scaler\", StandardScaler()), (\"model\", Ridge(alpha=10))])\n",
    "final_ridge.fit(X_hist, y_hist)\n",
    "\n",
    "beta = final_ridge.named_steps[\"model\"].coef_\n",
    "b0 = final_ridge.named_steps[\"model\"].intercept_\n",
    "\n",
    "eq = pd.DataFrame({\"feature\": col_num, \"beta_std\": beta}).sort_values(\"beta_std\", key=np.abs, ascending=False)\n",
    "print(\"Intercept (en escala del target):\", b0)\n",
    "eq\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cca9e58d",
   "metadata": {},
   "source": [
    "\n",
    "## Ecuacion Formal del Modelo Ridge\n",
    "\n",
    "El modelo corresponde a una regresion lineal con regularizacion L2 (Ridge), entrenada sobre variables estandarizadas.\n",
    "\n",
    "---\n",
    "\n",
    "### 1. Transformacion de las variables\n",
    "\n",
    "Cada variable explicativa fue estandarizada mediante la transformacion z-score:\n",
    "\n",
    "$$\n",
    "Z_i = \\frac{x_i - \\mu_i}{\\sigma_i}\n",
    "$$\n",
    "\n",
    "donde:\n",
    "\n",
    "- $x_i$ es el valor observado de la variable $i$  \n",
    "- $\\mu_i$ es la media de la variable $x_i$  \n",
    "- $\\sigma_i$ es la desviacion estandar de $x_i$\n",
    "\n",
    "Esta transformacion centra las variables en cero y las escala a varianza unitaria.\n",
    "\n",
    "---\n",
    "\n",
    "### 2. Forma general del modelo\n",
    "\n",
    "El modelo Ridge puede expresarse como:\n",
    "\n",
    "$$\n",
    "\\hat{y} = \\beta_0 + \\sum_{i=1}^{p} \\beta_i Z_i\n",
    "$$\n",
    "\n",
    "donde:\n",
    "\n",
    "- $\\beta_0$ es el intercepto  \n",
    "- $\\beta_i$ son los coeficientes estandarizados  \n",
    "- $Z_i$ son las variables transformadas  \n",
    "\n",
    "En notacion vectorial:\n",
    "\n",
    "$$\n",
    "\\hat{y} = \\beta_0 + \\boldsymbol{\\beta}^\\top \\mathbf{Z}\n",
    "$$\n",
    "\n",
    "---\n",
    "### Coeficientes estandarizados (beta_std)\n",
    "\n",
    "| Variable              | beta_std  | Interpretacion del signo |\n",
    "|-----------------------|----------:|--------------------------|\n",
    "| viajes_realizados     | 1039.77   | Aumenta el ingreso       |\n",
    "| precio_promedio_viaje | 740.45    | Aumenta el ingreso       |\n",
    "| incentivo_bono        | 106.62    | Aumenta el ingreso       |\n",
    "| cancelaciones_pct     | -31.13    | Reduce el ingreso        |\n",
    "| rating_promedio       | 25.41     | Aumenta el ingreso       |\n",
    "| horas_conectado       | 18.32     | Aumenta el ingreso       |\n",
    "| combustible_indice    | -17.45    | Reduce el ingreso        |\n",
    "| antiguedad_meses      | 1.10      | Impacto marginal         |\n",
    "\n",
    "\n",
    "### 3. Ecuacion estimada\n",
    "\n",
    "Sustituyendo los valores obtenidos:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\hat{y} =\\;& 4706.48 \\\\\n",
    "&+ 1039.77\\, Z_{viajes\\_realizados} \\\\\n",
    "&+ 740.45\\, Z_{precio\\_promedio\\_viaje} \\\\\n",
    "&+ 106.62\\, Z_{incentivo\\_bono} \\\\\n",
    "&- 31.13\\, Z_{cancelaciones\\_pct} \\\\\n",
    "&+ 25.41\\, Z_{rating\\_promedio} \\\\\n",
    "&+ 18.32\\, Z_{horas\\_conectado} \\\\\n",
    "&- 17.45\\, Z_{combustible\\_indice} \\\\\n",
    "&+ 1.10\\, Z_{antiguedad\\_meses}\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "### 4. Interpretacion Formal\n",
    "\n",
    "Cada coeficiente $\\beta_i$ representa el cambio esperado en el ingreso mensual ante un incremento de una desviacion estandar en la variable correspondiente, manteniendo las demas constantes.\n",
    "\n",
    "En terminos estructurales, las variables dominantes del modelo son:\n",
    "\n",
    "$$\n",
    "viajes\\_realizados \\quad \\text{y} \\quad precio\\_promedio\\_viaje\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "### 5. Formulacion del Problema Ridge\n",
    "\n",
    "El modelo Ridge estima los coeficientes resolviendo:\n",
    "\n",
    "$$\n",
    "\\min_{\\boldsymbol{\\beta}}\n",
    "\\left(\n",
    "\\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2\n",
    "+ \\lambda \\sum_{j=1}^{p} \\beta_j^2\n",
    "\\right)\n",
    "$$\n",
    "\n",
    "donde:\n",
    "\n",
    "- $\\lambda$ controla el grado de penalizacion L2  \n",
    "- La penalizacion reduce la magnitud de los coeficientes  \n",
    "- Se mejora la estabilidad y se reduce la varianza del modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f9f7a12",
   "metadata": {},
   "source": [
    "## 17) Resumen ejecutivo (que te llevas para clase)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7aed1a5",
   "metadata": {},
   "source": [
    "- **VIF** te muestra si las variables numericas estan pisandose entre si (multicolinealidad).  \n",
    "- **Regularizacion** (Ridge/Lasso/ElasticNet) estabiliza coeficientes y mejora generalizacion en datasets con colinealidad.  \n",
    "- **Validacion temporal** (2025) + metricas por mes = backtesting realista.  \n",
    "- **Rolling window** y **walk-forward** simulan produccion: el mundo cambia y el modelo se recalibra.  \n",
    "- **Permutation Importance** + **SHAP** te dan interpretabilidad solida para modelos no lineales.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "clases_ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
