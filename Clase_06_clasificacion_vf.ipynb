{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f0c86c47",
   "metadata": {},
   "source": [
    "# Masterclass Magistral: Clasificación de Mora (RCC) – Notebook Profesional V6\n",
    "**Caso práctico:** Predicción de mora a 30 días en los próximos 3 meses.\n",
    "\n",
    "Este notebook está diseñado para:\n",
    "- **Clase magistral** (conceptos + práctica)\n",
    "- **Estándar banca/producción** (anti-leakage, validación temporal, drift)\n",
    "\n",
    "Modelos evaluados (5):\n",
    "1) Regresión Logística (baseline regulatorio)\n",
    "2) Random Forest\n",
    "3) XGBoost (boosting)\n",
    "4) LightGBM (boosting)\n",
    "5) CatBoost (boosting con categóricas nativas)\n",
    "\n",
    "Métricas clave:\n",
    "- ROC-AUC\n",
    "- PR-AUC\n",
    "- **GINI = 2·AUC − 1**\n",
    "- **KS = max(TPR − FPR)**\n",
    "- **Lift Top 10%**\n",
    "- **PSI** (drift de variables y drift del score)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57d75301",
   "metadata": {},
   "source": [
    "## 0. Reglas anti-leakage (críticas en banca)\n",
    "- `id_cliente` **NO** es feature (evita memorizar clientes).\n",
    "- `periodo` **NO** es feature (se usa para split temporal y monitoreo).\n",
    "- Split **estrictamente temporal** por `periodo`.\n",
    "- Todas las transformaciones se entrenan **solo con TRAIN** y luego se aplican a TEST/OOT.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57691d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================\n",
    "# 1) Imports y configuración\n",
    "# ===============================\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score, roc_curve, precision_recall_curve\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)\n",
    "\n",
    "# Columnas confirmadas del dataset\n",
    "ID_COL = \"id_cliente\"\n",
    "TIME_COL = \"periodo\"\n",
    "TARGET = \"mora_30d_next3m\"\n",
    "\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2efa144a",
   "metadata": {},
   "source": [
    "## 2. Carga de datos + validación básica\n",
    "\n",
    "Este notebook está pensado para correr **sin copiar archivos manualmente**.\n",
    "\n",
    "- Si `dataset_mora.csv` existe en el mismo folder, se carga desde disco.\n",
    "- Si no existe, se descarga automáticamente desde el **raw URL del repo Git** (GitHub).\n",
    "\n",
    "> Si tu repo/branch/ruta cambia, solo actualiza `DATA_URL` en la celda siguiente.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "881899fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# 2) Carga de datos (GitHub raw) + fallback local\n",
    "# ==========================================\n",
    "GITHUB_RAW = \"https://raw.githubusercontent.com/josefrodrim/ML-course/main/data/dataset_mora.csv\"\n",
    "LOCAL_PATH = \"data/dataset_mora.csv\"  # si clonan el repo y ejecutan desde la raíz\n",
    "\n",
    "try:\n",
    "    df = pd.read_csv(GITHUB_RAW)\n",
    "    print(\"Dataset cargado desde GitHub \")\n",
    "except Exception as e:\n",
    "    print(\"No se pudo cargar desde GitHub. Intentando local...\")\n",
    "    df = pd.read_csv(LOCAL_PATH)\n",
    "    print(\"Dataset cargado desde ruta local \")\n",
    "\n",
    "print(\"Shape:\", df.shape)\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0861099d",
   "metadata": {},
   "source": [
    "## 3. Limpieza de tipos (dtype cleaning)\n",
    "En datasets reales, algunas variables numéricas vienen como texto (por comas, % o separadores). Esto rompe LightGBM/XGBoost y distorsiona el preprocesamiento.\n",
    "\n",
    "**Regla:** convertir a numérico con `errors='coerce'` y manejar missing con imputación en pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41d3a4c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================\n",
    "# 3) Limpieza de dtypes\n",
    "# ===============================\n",
    "df = df.copy()\n",
    "\n",
    "# numéricas esperadas (según columnas del dataset)\n",
    "num_should_be = [\n",
    "    \"edad\", \"ingreso_mensual\", \"score_bureau\", \"num_lineas\", \"max_mora_12m\", \"mora_30d_12m\",\n",
    "    \"saldo_total\", \"utilizacion_tc\", \"antig_laboral_anios\", \"antig_banca_anios\"\n",
    "]\n",
    "\n",
    "for c in num_should_be:\n",
    "    if c in df.columns:\n",
    "        df[c] = (\n",
    "            df[c].astype(str)\n",
    "                .str.replace(\",\", \"\", regex=False)\n",
    "                .str.replace(\"%\", \"\", regex=False)\n",
    "                .str.strip()\n",
    "        )\n",
    "        df[c] = pd.to_numeric(df[c], errors=\"coerce\")\n",
    "\n",
    "# categóricas esperadas\n",
    "cat_should_be = [\"sexo\", \"region\", \"segmento\", \"producto_principal\", \"canal_origen\"]\n",
    "for c in cat_should_be:\n",
    "    if c in df.columns:\n",
    "        df[c] = df[c].astype(\"string\")\n",
    "\n",
    "print(\"Tipos (numéricas):\")\n",
    "display(df[num_should_be].dtypes)\n",
    "print(\"Tipos (categóricas):\")\n",
    "display(df[cat_should_be].dtypes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e263931a",
   "metadata": {},
   "source": [
    "## 4. Normalización temporal de `periodo`\n",
    "Creamos `periodo_ord` como YYYYMM entero para ordenar, split temporal y análisis de drift. Soporta formatos `YYYYMM`, `YYYY-MM`, fechas, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fac8c4a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================\n",
    "# 4) Normalizar 'periodo' -> periodo_ord (YYYYMM)\n",
    "# ===============================\n",
    "def to_period_ord(s: pd.Series) -> pd.Series:\n",
    "    s_str = s.astype(str).str.replace(r\"[^0-9]\", \"\", regex=True)\n",
    "    ok = s_str.str.len() == 6\n",
    "    out = pd.Series(pd.NA, index=s.index, dtype=\"Int64\")\n",
    "    out.loc[ok] = s_str.loc[ok].astype(\"Int64\")\n",
    "    if out.isna().any():\n",
    "        dt = pd.to_datetime(s, errors=\"coerce\")\n",
    "        out2 = (dt.dt.year * 100 + dt.dt.month).astype(\"Int64\")\n",
    "        out = out.fillna(out2)\n",
    "    return out\n",
    "\n",
    "df[\"periodo_ord\"] = to_period_ord(df[TIME_COL])\n",
    "assert df[\"periodo_ord\"].isna().mean() == 0, \"No se pudo parsear 'periodo' en algunos registros.\"\n",
    "\n",
    "df = df.sort_values(\"periodo_ord\").reset_index(drop=True)\n",
    "print(\"Rango periodo_ord:\", int(df[\"periodo_ord\"].min()), \"->\", int(df[\"periodo_ord\"].max()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43d2de9a",
   "metadata": {},
   "source": [
    "## 5. EDA mínimo (target + estabilidad temporal)\n",
    "- Distribución del target\n",
    "- Tasa de mora por periodo (drift del target)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51dacaa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================\n",
    "# 5) EDA: Target\n",
    "# ===============================\n",
    "plt.figure()\n",
    "vals = df[TARGET].value_counts().sort_index()\n",
    "plt.bar(vals.index.astype(str), vals.values)\n",
    "plt.title(\"Distribución del Target\")\n",
    "plt.xlabel(TARGET)\n",
    "plt.ylabel(\"Conteo\")\n",
    "plt.show()\n",
    "\n",
    "print(\"Tasa de mora global:\", float(df[TARGET].mean()))\n",
    "\n",
    "# Tasa de mora por periodo\n",
    "rate_by_period = df.groupby(\"periodo_ord\")[TARGET].mean()\n",
    "plt.figure()\n",
    "plt.plot(rate_by_period.index.astype(str), rate_by_period.values)\n",
    "plt.title(\"Tasa de mora por periodo\")\n",
    "plt.xlabel(\"periodo_ord (YYYYMM)\")\n",
    "plt.ylabel(\"Tasa mora\")\n",
    "plt.xticks(rotation=60)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99de4ad7",
   "metadata": {},
   "source": [
    "## 6. Split temporal (Train / Test / OOT)\n",
    "Split por **periodos únicos** para no partir un periodo entre conjuntos.\n",
    "\n",
    "Por defecto:\n",
    "- Train: 70% periodos\n",
    "- Test: 15% periodos\n",
    "- OOT: 15% periodos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc675750",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================\n",
    "# 6) Split temporal por periodos únicos\n",
    "# ===============================\n",
    "periods = sorted(df[\"periodo_ord\"].unique())\n",
    "n = len(periods)\n",
    "\n",
    "train_periods = periods[: int(n*0.70)]\n",
    "test_periods  = periods[int(n*0.70): int(n*0.85)]\n",
    "oot_periods   = periods[int(n*0.85):]\n",
    "\n",
    "train_df = df[df[\"periodo_ord\"].isin(train_periods)].copy()\n",
    "test_df  = df[df[\"periodo_ord\"].isin(test_periods)].copy()\n",
    "oot_df   = df[df[\"periodo_ord\"].isin(oot_periods)].copy()\n",
    "\n",
    "print(\"Train periods:\", (min(train_periods), max(train_periods)), \"n=\", len(train_periods), \"rows=\", train_df.shape[0])\n",
    "print(\"Test  periods:\", (min(test_periods),  max(test_periods)),  \"n=\", len(test_periods),  \"rows=\", test_df.shape[0])\n",
    "print(\"OOT   periods:\", (min(oot_periods),   max(oot_periods)),   \"n=\", len(oot_periods),   \"rows=\", oot_df.shape[0])\n",
    "\n",
    "for name, d in [(\"TRAIN\", train_df), (\"TEST\", test_df), (\"OOT\", oot_df)]:\n",
    "    print(name, \"target_rate=\", round(float(d[TARGET].mean()), 4), \"n=\", len(d))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daa3f9ae",
   "metadata": {},
   "source": [
    "## 7. Definición de features (excluyendo ID y tiempo)\n",
    "Excluimos: `id_cliente`, `periodo`, `periodo_ord`, `target`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8680f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================\n",
    "# 7) Features\n",
    "# ===============================\n",
    "DROP_COLS = [ID_COL, TIME_COL, \"periodo_ord\", TARGET]\n",
    "features = [c for c in df.columns if c not in DROP_COLS]\n",
    "\n",
    "X_train = train_df[features]\n",
    "y_train = train_df[TARGET].astype(int)\n",
    "\n",
    "X_test  = test_df[features]\n",
    "y_test  = test_df[TARGET].astype(int)\n",
    "\n",
    "X_oot   = oot_df[features]\n",
    "y_oot   = oot_df[TARGET].astype(int)\n",
    "\n",
    "num_cols = X_train.select_dtypes(include=[\"int64\",\"float64\",\"int32\",\"float32\"]).columns.tolist()\n",
    "cat_cols = [c for c in features if c not in num_cols]\n",
    "\n",
    "print(\"Features:\", len(features))\n",
    "print(\"Numéricas:\", len(num_cols))\n",
    "print(\"Categóricas:\", len(cat_cols), cat_cols)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e194667a",
   "metadata": {},
   "source": [
    "## 8. Correlación (numéricas) + alerta leakage\n",
    "Mostramos correlación de variables numéricas y su correlación con el target. Buscamos:\n",
    "- multicolinealidad alta entre features\n",
    "- features con correlación excesiva con el target (posible leakage)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26f330e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================\n",
    "# 8) Correlación numérica\n",
    "# ===============================\n",
    "num_plus_target = train_df[num_cols + [TARGET]].copy()\n",
    "\n",
    "corr = num_plus_target.corr(numeric_only=True)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.imshow(corr.values, aspect=\"auto\")\n",
    "plt.colorbar()\n",
    "plt.xticks(range(len(corr.columns)), corr.columns, rotation=90)\n",
    "plt.yticks(range(len(corr.index)), corr.index)\n",
    "plt.title(\"Matriz de correlación (TRAIN) - variables numéricas + target\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "corr_target = corr[TARGET].drop(TARGET).sort_values(ascending=False)\n",
    "print(\"Top correlación con target (abs):\")\n",
    "display(corr_target.reindex(corr_target.abs().sort_values(ascending=False).index).head(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82dcabb3",
   "metadata": {},
   "source": [
    "## 9. Preprocesamiento\n",
    "Para LR/RF/LGBM: imputación + OneHotEncoder para categóricas. \n",
    "- LR: escalamos numéricas\n",
    "- Árboles: no escalamos numéricas\n",
    "\n",
    "**Nota:** para CatBoost no usamos OHE; usa categóricas nativas.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf06199a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================\n",
    "# 9) Preprocesamiento (OHE)\n",
    "# ===============================\n",
    "num_pipe_no_scale = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\"))\n",
    "])\n",
    "\n",
    "num_pipe_scale = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"scaler\", StandardScaler())\n",
    "])\n",
    "\n",
    "cat_pipe = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "    (\"ohe\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
    "])\n",
    "\n",
    "preprocess_lr = ColumnTransformer([\n",
    "    (\"num\", num_pipe_scale, num_cols),\n",
    "    (\"cat\", cat_pipe, cat_cols)\n",
    "])\n",
    "\n",
    "preprocess_tree = ColumnTransformer([\n",
    "    (\"num\", num_pipe_no_scale, num_cols),\n",
    "    (\"cat\", cat_pipe, cat_cols)\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de06aff6",
   "metadata": {},
   "source": [
    "## 10. Métricas (definiciones)\n",
    "- **ROC-AUC:** capacidad de ranking global.\n",
    "- **PR-AUC:** recomendado en desbalance.\n",
    "- **GINI:** estándar banca: `GINI = 2*AUC - 1`.\n",
    "- **KS:** separación máxima entre distribuciones de score de buenos/malos.\n",
    "- **Lift Top 10%:** concentración de eventos en el decil superior.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1203c4b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================\n",
    "# 10) Métricas\n",
    "# ===============================\n",
    "def gini_from_auc(auc): \n",
    "    return 2*auc - 1\n",
    "\n",
    "def ks_statistic(y_true, y_prob):\n",
    "    fpr, tpr, _ = roc_curve(y_true, y_prob)\n",
    "    return float(np.max(tpr - fpr))\n",
    "\n",
    "def lift_top_decile(y_true, y_prob):\n",
    "    tmp = pd.DataFrame({\"y\": y_true, \"p\": y_prob}).sort_values(\"p\", ascending=False)\n",
    "    k = max(1, int(len(tmp)*0.10))\n",
    "    return float(tmp.head(k)[\"y\"].mean() / tmp[\"y\"].mean())\n",
    "\n",
    "def metrics_pack(y_true, y_prob):\n",
    "    auc = roc_auc_score(y_true, y_prob)\n",
    "    return {\n",
    "        \"AUC\": float(auc),\n",
    "        \"GINI\": float(gini_from_auc(auc)),\n",
    "        \"PR_AUC\": float(average_precision_score(y_true, y_prob)),\n",
    "        \"KS\": float(ks_statistic(y_true, y_prob)),\n",
    "        \"LIFT_10\": float(lift_top_decile(y_true, y_prob)),\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3ea6b47",
   "metadata": {},
   "source": [
    "## 11. PSI (Population Stability Index)\n",
    "Mide drift entre dos distribuciones.\n",
    "\n",
    "Interpretación típica:\n",
    "- PSI < 0.10: estable\n",
    "- 0.10–0.25: drift moderado\n",
    "- > 0.25: drift fuerte\n",
    "\n",
    "Calcularemos:\n",
    "- PSI por variable numérica (TRAIN vs OOT)\n",
    "- PSI del score (TRAIN vs OOT)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e554da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================\n",
    "# 11) PSI\n",
    "# ===============================\n",
    "def psi_numeric(expected: np.ndarray, actual: np.ndarray, buckets: int = 10) -> float:\n",
    "    expected = np.asarray(expected)\n",
    "    actual = np.asarray(actual)\n",
    "    expected = expected[~np.isnan(expected)]\n",
    "    actual = actual[~np.isnan(actual)]\n",
    "    if len(expected) == 0 or len(actual) == 0:\n",
    "        return np.nan\n",
    "\n",
    "    breakpoints = np.percentile(expected, np.linspace(0, 100, buckets + 1))\n",
    "    breakpoints = np.unique(breakpoints)\n",
    "    if len(breakpoints) <= 2:\n",
    "        return 0.0\n",
    "\n",
    "    e_cnt, _ = np.histogram(expected, bins=breakpoints)\n",
    "    a_cnt, _ = np.histogram(actual, bins=breakpoints)\n",
    "\n",
    "    e_perc = e_cnt / max(e_cnt.sum(), 1)\n",
    "    a_perc = a_cnt / max(a_cnt.sum(), 1)\n",
    "\n",
    "    eps = 1e-6\n",
    "    return float(np.sum((a_perc - e_perc) * np.log((a_perc + eps) / (e_perc + eps))))\n",
    "\n",
    "# PSI por variable numérica (TRAIN vs OOT)\n",
    "psi_rows = []\n",
    "for c in num_cols:\n",
    "    psi_val = psi_numeric(train_df[c].values, oot_df[c].values, buckets=10)\n",
    "    psi_rows.append((c, psi_val))\n",
    "psi_df = pd.DataFrame(psi_rows, columns=[\"feature\", \"psi_train_vs_oot\"]).sort_values(\"psi_train_vs_oot\", ascending=False)\n",
    "display(psi_df.head(15))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5288ac0d",
   "metadata": {},
   "source": [
    "## 12. Modelamiento\n",
    "Manejo de desbalance:\n",
    "- LR/RF: `class_weight='balanced'`\n",
    "- XGB/LGBM: `scale_pos_weight = #neg / #pos` (en TRAIN)\n",
    "- CatBoost: `class_weights=[w_neg, w_pos]`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3947e485",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================\n",
    "# 12) scale_pos_weight (TRAIN)\n",
    "# ===============================\n",
    "pos = int(y_train.sum())\n",
    "neg = int(len(y_train) - pos)\n",
    "scale_pos_weight = float(neg / max(pos, 1))\n",
    "print(\"Pos:\", pos, \"Neg:\", neg, \"scale_pos_weight:\", round(scale_pos_weight, 4))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46dcc5d8",
   "metadata": {},
   "source": [
    "### 12.1 Logistic Regression (pipeline)\n",
    "Baseline regulatorio: interpretabilidad alta, performance razonable si features están bien."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2ac6682",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_model = Pipeline([\n",
    "    (\"prep\", preprocess_lr),\n",
    "    (\"clf\", LogisticRegression(\n",
    "        max_iter=3000,\n",
    "        class_weight=\"balanced\",\n",
    "        solver=\"lbfgs\",\n",
    "        random_state=RANDOM_STATE\n",
    "    ))\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50bc8b39",
   "metadata": {},
   "source": [
    "### 12.2 Random Forest (pipeline)\n",
    "Modelo estable (bagging) pero a veces menor poder que boosting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4a11ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model = Pipeline([\n",
    "    (\"prep\", preprocess_tree),\n",
    "    (\"clf\", RandomForestClassifier(\n",
    "        n_estimators=600,\n",
    "        max_depth=10,\n",
    "        min_samples_leaf=50,\n",
    "        class_weight=\"balanced\",\n",
    "        n_jobs=-1,\n",
    "        random_state=RANDOM_STATE\n",
    "    ))\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36884788",
   "metadata": {},
   "source": [
    "### 12.3 XGBoost PRO (early stopping) – robusto a versiones\n",
    "Usamos `xgb.train()` con `DMatrix`, que suele soportar `early_stopping_rounds` incluso en versiones antiguas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1805299c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocesamos con OHE para XGB\n",
    "X_tr_xgb = preprocess_tree.fit_transform(X_train)\n",
    "X_te_xgb = preprocess_tree.transform(X_test)\n",
    "X_oo_xgb = preprocess_tree.transform(X_oot)\n",
    "\n",
    "dtrain = xgb.DMatrix(X_tr_xgb, label=y_train)\n",
    "dtest  = xgb.DMatrix(X_te_xgb, label=y_test)\n",
    "doot   = xgb.DMatrix(X_oo_xgb, label=y_oot)\n",
    "\n",
    "xgb_params = {\n",
    "    \"objective\": \"binary:logistic\",\n",
    "    \"eval_metric\": \"auc\",\n",
    "    \"eta\": 0.03,\n",
    "    \"max_depth\": 5,\n",
    "    \"subsample\": 0.8,\n",
    "    \"colsample_bytree\": 0.8,\n",
    "    \"min_child_weight\": 5,\n",
    "    \"lambda\": 2.0,\n",
    "    \"scale_pos_weight\": scale_pos_weight,\n",
    "    \"seed\": RANDOM_STATE,\n",
    "}\n",
    "\n",
    "watchlist = [(dtrain, \"train\"), (dtest, \"test\")]\n",
    "\n",
    "xgb_bst = xgb.train(\n",
    "    params=xgb_params,\n",
    "    dtrain=dtrain,\n",
    "    num_boost_round=5000,\n",
    "    evals=watchlist,\n",
    "    early_stopping_rounds=100,\n",
    "    verbose_eval=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "721e578a",
   "metadata": {},
   "source": [
    "### 12.4 LightGBM robusto\n",
    "Entrenamos sobre matriz ya transformada (OHE), evitando problemas de dtypes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dd68acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocesamos con OHE para LGBM\n",
    "X_tr_lgb = preprocess_tree.fit_transform(X_train)\n",
    "X_te_lgb = preprocess_tree.transform(X_test)\n",
    "X_oo_lgb = preprocess_tree.transform(X_oot)\n",
    "\n",
    "lgb_clf = lgb.LGBMClassifier(\n",
    "    n_estimators=5000,\n",
    "    learning_rate=0.03,\n",
    "    num_leaves=31,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    reg_lambda=2.0,\n",
    "    min_child_samples=100,\n",
    "    scale_pos_weight=scale_pos_weight,\n",
    "    random_state=RANDOM_STATE,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Algunas versiones aceptan early_stopping_rounds; otras no.\n",
    "# Intentamos de forma segura.\n",
    "try:\n",
    "    lgb_clf.fit(\n",
    "        X_tr_lgb, y_train,\n",
    "        eval_set=[(X_te_lgb, y_test)],\n",
    "        eval_metric=\"auc\",\n",
    "        early_stopping_rounds=100,\n",
    "        verbose=False\n",
    "    )\n",
    "except TypeError:\n",
    "    lgb_clf.fit(\n",
    "        X_tr_lgb, y_train,\n",
    "        eval_set=[(X_te_lgb, y_test)],\n",
    "        eval_metric=\"auc\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73cdbb31",
   "metadata": {},
   "source": [
    "### 12.5 CatBoost (categóricas nativas)\n",
    "CatBoost suele funcionar muy bien en datasets con categóricas reales (segmento, producto, canal, región)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a9a65d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imputación simple para CatBoost (sin OHE)\n",
    "X_train_cb = X_train.copy()\n",
    "X_test_cb  = X_test.copy()\n",
    "X_oot_cb   = X_oot.copy()\n",
    "\n",
    "# numéricas\n",
    "for c in num_cols:\n",
    "    med = X_train_cb[c].median()\n",
    "    X_train_cb[c] = X_train_cb[c].fillna(med)\n",
    "    X_test_cb[c]  = X_test_cb[c].fillna(med)\n",
    "    X_oot_cb[c]   = X_oot_cb[c].fillna(med)\n",
    "\n",
    "# categóricas (string)\n",
    "for c in cat_cols:\n",
    "    mode = X_train_cb[c].mode(dropna=True)\n",
    "    fill = mode.iloc[0] if len(mode) else \"MISSING\"\n",
    "    X_train_cb[c] = X_train_cb[c].fillna(fill).astype(str)\n",
    "    X_test_cb[c]  = X_test_cb[c].fillna(fill).astype(str)\n",
    "    X_oot_cb[c]   = X_oot_cb[c].fillna(fill).astype(str)\n",
    "\n",
    "cat_features_idx = [X_train_cb.columns.get_loc(c) for c in cat_cols]\n",
    "\n",
    "w_neg = 1.0\n",
    "w_pos = scale_pos_weight\n",
    "\n",
    "cat_clf = CatBoostClassifier(\n",
    "    iterations=5000,\n",
    "    learning_rate=0.03,\n",
    "    depth=6,\n",
    "    l2_leaf_reg=6,\n",
    "    loss_function=\"Logloss\",\n",
    "    eval_metric=\"AUC\",\n",
    "    random_seed=RANDOM_STATE,\n",
    "    verbose=0,\n",
    "    class_weights=[w_neg, w_pos]\n",
    ")\n",
    "\n",
    "cat_clf.fit(\n",
    "    X_train_cb, y_train,\n",
    "    cat_features=cat_features_idx,\n",
    "    eval_set=(X_test_cb, y_test),\n",
    "    use_best_model=True,\n",
    "    verbose=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1fee2f4",
   "metadata": {},
   "source": [
    "## 13. Evaluación unificada + tabla comparativa\n",
    "Reportamos Train/Test/OOT + gaps para detectar overfitting y drift.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61510bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_pipeline(name, model):\n",
    "    model.fit(X_train, y_train)\n",
    "    p_tr  = model.predict_proba(X_train)[:, 1]\n",
    "    p_te  = model.predict_proba(X_test)[:, 1]\n",
    "    p_oo  = model.predict_proba(X_oot)[:, 1]\n",
    "    return p_tr, p_te, p_oo\n",
    "\n",
    "results = []\n",
    "preds_map = {}\n",
    "\n",
    "# Logistic\n",
    "p_tr, p_te, p_oo = eval_pipeline(\"Logistic\", log_model)\n",
    "preds_map[\"Logistic\"] = {\"p_train\": p_tr, \"p_test\": p_te, \"p_oot\": p_oo}\n",
    "\n",
    "m_tr, m_te, m_oo = metrics_pack(y_train, p_tr), metrics_pack(y_test, p_te), metrics_pack(y_oot, p_oo)\n",
    "results.append({\n",
    "    \"Model\":\"Logistic\",\n",
    "    \"Train_AUC\": m_tr[\"AUC\"], \"Test_AUC\": m_te[\"AUC\"], \"OOT_AUC\": m_oo[\"AUC\"],\n",
    "    \"OOT_GINI\": m_oo[\"GINI\"], \"OOT_KS\": m_oo[\"KS\"], \"OOT_LIFT10\": m_oo[\"LIFT_10\"], \"OOT_PR_AUC\": m_oo[\"PR_AUC\"],\n",
    "    \"Gap_Train_Test_AUC\": m_tr[\"AUC\"] - m_te[\"AUC\"],\n",
    "    \"Gap_Test_OOT_AUC\": m_te[\"AUC\"] - m_oo[\"AUC\"],\n",
    "})\n",
    "\n",
    "# RandomForest\n",
    "p_tr, p_te, p_oo = eval_pipeline(\"RandomForest\", rf_model)\n",
    "preds_map[\"RandomForest\"] = {\"p_train\": p_tr, \"p_test\": p_te, \"p_oot\": p_oo}\n",
    "\n",
    "m_tr, m_te, m_oo = metrics_pack(y_train, p_tr), metrics_pack(y_test, p_te), metrics_pack(y_oot, p_oo)\n",
    "results.append({\n",
    "    \"Model\":\"RandomForest\",\n",
    "    \"Train_AUC\": m_tr[\"AUC\"], \"Test_AUC\": m_te[\"AUC\"], \"OOT_AUC\": m_oo[\"AUC\"],\n",
    "    \"OOT_GINI\": m_oo[\"GINI\"], \"OOT_KS\": m_oo[\"KS\"], \"OOT_LIFT10\": m_oo[\"LIFT_10\"], \"OOT_PR_AUC\": m_oo[\"PR_AUC\"],\n",
    "    \"Gap_Train_Test_AUC\": m_tr[\"AUC\"] - m_te[\"AUC\"],\n",
    "    \"Gap_Test_OOT_AUC\": m_te[\"AUC\"] - m_oo[\"AUC\"],\n",
    "})\n",
    "\n",
    "# XGBoost (xgb.train)\n",
    "p_tr = xgb_bst.predict(dtrain)\n",
    "p_te = xgb_bst.predict(dtest)\n",
    "p_oo = xgb_bst.predict(doot)\n",
    "preds_map[\"XGBoost\"] = {\"p_train\": p_tr, \"p_test\": p_te, \"p_oot\": p_oo}\n",
    "\n",
    "m_tr, m_te, m_oo = metrics_pack(y_train, p_tr), metrics_pack(y_test, p_te), metrics_pack(y_oot, p_oo)\n",
    "results.append({\n",
    "    \"Model\":\"XGBoost\",\n",
    "    \"Train_AUC\": m_tr[\"AUC\"], \"Test_AUC\": m_te[\"AUC\"], \"OOT_AUC\": m_oo[\"AUC\"],\n",
    "    \"OOT_GINI\": m_oo[\"GINI\"], \"OOT_KS\": m_oo[\"KS\"], \"OOT_LIFT10\": m_oo[\"LIFT_10\"], \"OOT_PR_AUC\": m_oo[\"PR_AUC\"],\n",
    "    \"Gap_Train_Test_AUC\": m_tr[\"AUC\"] - m_te[\"AUC\"],\n",
    "    \"Gap_Test_OOT_AUC\": m_te[\"AUC\"] - m_oo[\"AUC\"],\n",
    "})\n",
    "\n",
    "# LightGBM\n",
    "p_tr = lgb_clf.predict_proba(X_tr_lgb)[:, 1]\n",
    "p_te = lgb_clf.predict_proba(X_te_lgb)[:, 1]\n",
    "p_oo = lgb_clf.predict_proba(X_oo_lgb)[:, 1]\n",
    "preds_map[\"LightGBM\"] = {\"p_train\": p_tr, \"p_test\": p_te, \"p_oot\": p_oo}\n",
    "\n",
    "m_tr, m_te, m_oo = metrics_pack(y_train, p_tr), metrics_pack(y_test, p_te), metrics_pack(y_oot, p_oo)\n",
    "results.append({\n",
    "    \"Model\":\"LightGBM\",\n",
    "    \"Train_AUC\": m_tr[\"AUC\"], \"Test_AUC\": m_te[\"AUC\"], \"OOT_AUC\": m_oo[\"AUC\"],\n",
    "    \"OOT_GINI\": m_oo[\"GINI\"], \"OOT_KS\": m_oo[\"KS\"], \"OOT_LIFT10\": m_oo[\"LIFT_10\"], \"OOT_PR_AUC\": m_oo[\"PR_AUC\"],\n",
    "    \"Gap_Train_Test_AUC\": m_tr[\"AUC\"] - m_te[\"AUC\"],\n",
    "    \"Gap_Test_OOT_AUC\": m_te[\"AUC\"] - m_oo[\"AUC\"],\n",
    "})\n",
    "\n",
    "# CatBoost\n",
    "p_tr = cat_clf.predict_proba(X_train_cb)[:, 1]\n",
    "p_te = cat_clf.predict_proba(X_test_cb)[:, 1]\n",
    "p_oo = cat_clf.predict_proba(X_oot_cb)[:, 1]\n",
    "preds_map[\"CatBoost\"] = {\"p_train\": p_tr, \"p_test\": p_te, \"p_oot\": p_oo}\n",
    "\n",
    "m_tr, m_te, m_oo = metrics_pack(y_train, p_tr), metrics_pack(y_test, p_te), metrics_pack(y_oot, p_oo)\n",
    "results.append({\n",
    "    \"Model\":\"CatBoost\",\n",
    "    \"Train_AUC\": m_tr[\"AUC\"], \"Test_AUC\": m_te[\"AUC\"], \"OOT_AUC\": m_oo[\"AUC\"],\n",
    "    \"OOT_GINI\": m_oo[\"GINI\"], \"OOT_KS\": m_oo[\"KS\"], \"OOT_LIFT10\": m_oo[\"LIFT_10\"], \"OOT_PR_AUC\": m_oo[\"PR_AUC\"],\n",
    "    \"Gap_Train_Test_AUC\": m_tr[\"AUC\"] - m_te[\"AUC\"],\n",
    "    \"Gap_Test_OOT_AUC\": m_te[\"AUC\"] - m_oo[\"AUC\"],\n",
    "})\n",
    "\n",
    "results_df = pd.DataFrame(results).sort_values(\"OOT_GINI\", ascending=False).reset_index(drop=True)\n",
    "display(results_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fc1e76a",
   "metadata": {},
   "source": [
    "## 14. Gráficos comparativos\n",
    "A) Barras AUC (Train/Test/OOT)\n",
    "B) ROC en OOT\n",
    "C) PR Curve en OOT\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d94fe1b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A) Barras AUC\n",
    "plt.figure(figsize=(9,4))\n",
    "x = np.arange(len(results_df))\n",
    "plt.bar(x-0.2, results_df[\"Train_AUC\"], width=0.2, label=\"Train\")\n",
    "plt.bar(x,      results_df[\"Test_AUC\"],  width=0.2, label=\"Test\")\n",
    "plt.bar(x+0.2,  results_df[\"OOT_AUC\"],   width=0.2, label=\"OOT\")\n",
    "plt.xticks(x, results_df[\"Model\"], rotation=30)\n",
    "plt.title(\"AUC por modelo (Train/Test/OOT)\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# B) ROC OOT\n",
    "plt.figure()\n",
    "for name, pr in preds_map.items():\n",
    "    fpr, tpr, _ = roc_curve(y_oot, pr[\"p_oot\"])\n",
    "    plt.plot(fpr, tpr, label=name)\n",
    "plt.plot([0,1],[0,1], linestyle=\"--\")\n",
    "plt.title(\"ROC Curves (OOT)\")\n",
    "plt.xlabel(\"FPR\")\n",
    "plt.ylabel(\"TPR\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# C) PR Curve OOT\n",
    "plt.figure()\n",
    "for name, pr in preds_map.items():\n",
    "    prec, rec, _ = precision_recall_curve(y_oot, pr[\"p_oot\"])\n",
    "    plt.plot(rec, prec, label=name)\n",
    "plt.title(\"Precision-Recall Curves (OOT)\")\n",
    "plt.xlabel(\"Recall\")\n",
    "plt.ylabel(\"Precision\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48d4d49d",
   "metadata": {},
   "source": [
    "## 15. Lift / Gains (OOT)\n",
    "Mostramos **cumulative gain** para comparar capacidad de captura de morosos en el top de score.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11e977c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cumulative_gain(y_true, y_prob):\n",
    "    tmp = pd.DataFrame({\"y\": y_true, \"p\": y_prob}).sort_values(\"p\", ascending=False).reset_index(drop=True)\n",
    "    tmp[\"cum_events\"] = tmp[\"y\"].cumsum()\n",
    "    tmp[\"cum_event_rate\"] = tmp[\"cum_events\"] / max(tmp[\"y\"].sum(), 1)\n",
    "    tmp[\"pop_rate\"] = (np.arange(len(tmp)) + 1) / len(tmp)\n",
    "    return tmp[\"pop_rate\"].values, tmp[\"cum_event_rate\"].values\n",
    "\n",
    "plt.figure()\n",
    "for name, pr in preds_map.items():\n",
    "    x_pop, y_gain = cumulative_gain(y_oot.values, pr[\"p_oot\"])\n",
    "    plt.plot(x_pop, y_gain, label=name)\n",
    "plt.plot([0,1],[0,1], linestyle=\"--\")\n",
    "plt.title(\"Cumulative Gain (OOT)\")\n",
    "plt.xlabel(\"% población (ordenada por score desc)\")\n",
    "plt.ylabel(\"% eventos capturados\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bedcd197",
   "metadata": {},
   "source": [
    "## 16. PSI del score (TRAIN vs OOT)\n",
    "PSI del score es un control central en monitoreo de modelos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aa99e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PSI del score por modelo\n",
    "psi_score_rows = []\n",
    "for name, pr in preds_map.items():\n",
    "    psi_s = psi_numeric(pr[\"p_train\"], pr[\"p_oot\"], buckets=10)\n",
    "    psi_score_rows.append((name, psi_s))\n",
    "\n",
    "psi_score_df = pd.DataFrame(psi_score_rows, columns=[\"Model\", \"PSI_score_train_vs_oot\"]).sort_values(\"PSI_score_train_vs_oot\", ascending=False)\n",
    "display(psi_score_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5d9fb2d",
   "metadata": {},
   "source": [
    "## 17. Checklist final (producción)\n",
    "- Revisar features con correlación sospechosa con el target (leakage)\n",
    "- Variables con PSI alto (drift)\n",
    "- PSI del score (drift del score)\n",
    "- Gaps Train-Test / Test-OOT (overfit vs drift)\n",
    "\n",
    "Recomendación típica:\n",
    "- Si buscas **estabilidad**: prioriza menor gap + PSI bajo.\n",
    "- Si buscas **poder predictivo**: prioriza OOT_GINI alto, pero controla overfit.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ad19cad",
   "metadata": {},
   "source": [
    "# Estabilidad temporal del modelo (Monitoreo productivo)\n",
    "\n",
    "En producción, un modelo de riesgo se monitorea **en el tiempo**, no solo con una métrica global.\n",
    "\n",
    "En esta sección calculamos:\n",
    "\n",
    "- **GINI por mes** (para todos los meses del dataset)\n",
    "- **GINI móvil 3M** (suaviza ruido)\n",
    "- **Tendencia** (línea de tendencia del GINI)\n",
    "- **Alertas** (caídas relevantes vs baseline)\n",
    "- **GINI por segmento** (ej. región / segmento) para detectar degradación localizada\n",
    "\n",
    "> Nota: Para meses con target de una sola clase (todo 0 o todo 1), el AUC/GINI no se puede calcular; se reporta como `NaN`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b373dcec",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "def gini_from_auc(auc):\n",
    "    return 2 * auc - 1\n",
    "\n",
    "def gini_by_month(df_in, score_col, target_col, period_col):\n",
    "    def _auc_safe(x):\n",
    "        # AUC requiere 2 clases\n",
    "        if x[target_col].nunique() < 2:\n",
    "            return np.nan\n",
    "        return roc_auc_score(x[target_col], x[score_col])\n",
    "\n",
    "    out = (\n",
    "        df_in[[period_col, target_col, score_col]]\n",
    "        .groupby(period_col, as_index=False)\n",
    "        .apply(lambda x: _auc_safe(x))\n",
    "        .rename(columns={None: \"AUC\"})\n",
    "    )\n",
    "    # nb: el groupby+apply puede devolver columna 0 según versión\n",
    "    if 0 in out.columns and \"AUC\" not in out.columns:\n",
    "        out = out.rename(columns={0: \"AUC\"})\n",
    "    out[\"GINI\"] = out[\"AUC\"].map(lambda a: gini_from_auc(a) if pd.notnull(a) else np.nan)\n",
    "    return out.sort_values(period_col).reset_index(drop=True)\n",
    "\n",
    "def _score_full_dataset(best_model_name):\n",
    "    # Requiere que ya existan: df, features, preprocess_tree, preprocess_lr, \n",
    "    # y modelos entrenados: log_model, rf_model, bst (xgb.train), lgb_clf, cat_clf\n",
    "    X_full = df[features].copy()\n",
    "\n",
    "    if best_model_name == \"CatBoost\":\n",
    "        # CatBoost: usar el mismo preprocesamiento simple que hicimos para cb (imputación + str)\n",
    "        X_full_cb = X_full.copy()\n",
    "        for c in num_cols:\n",
    "            med = X_train[c].median()\n",
    "            X_full_cb[c] = pd.to_numeric(X_full_cb[c], errors=\"coerce\").fillna(med)\n",
    "        for c in cat_cols:\n",
    "            mode = X_train[c].mode(dropna=True)\n",
    "            fill = mode.iloc[0] if len(mode) else \"MISSING\"\n",
    "            X_full_cb[c] = X_full_cb[c].fillna(fill).astype(str)\n",
    "        scores = cat_clf.predict_proba(X_full_cb)[:, 1]\n",
    "        return scores\n",
    "\n",
    "    if best_model_name == \"XGBoost\":\n",
    "        X_full_x = preprocess_tree.transform(X_full)\n",
    "        dfull = xgb.DMatrix(X_full_x)\n",
    "        scores = bst.predict(dfull)\n",
    "        return scores\n",
    "\n",
    "    if best_model_name == \"LightGBM\":\n",
    "        X_full_l = preprocess_tree.transform(X_full)\n",
    "        scores = lgb_clf.predict_proba(X_full_l)[:, 1]\n",
    "        return scores\n",
    "\n",
    "    if best_model_name == \"RandomForest\":\n",
    "        scores = rf_model.predict_proba(X_full)[:, 1]\n",
    "        return scores\n",
    "\n",
    "    # Logistic (default)\n",
    "    scores = log_model.predict_proba(X_full)[:, 1]\n",
    "    return scores\n",
    "\n",
    "# 1) Selección del modelo a monitorear (top por OOT_GINI)\n",
    "best_model = results_df.sort_values(\"OOT_GINI\", ascending=False).iloc[0][\"Model\"]\n",
    "print(\"Modelo monitoreado:\", best_model)\n",
    "\n",
    "# 2) Score para TODO el dataset\n",
    "df = df.copy()\n",
    "df[\"score_model\"] = _score_full_dataset(best_model)\n",
    "\n",
    "# 3) GINI mensual\n",
    "gini_monthly = gini_by_month(df, \"score_model\", TARGET, \"periodo_ord\")\n",
    "display(gini_monthly.head(10))\n",
    "\n",
    "# 4) GINI móvil 3M\n",
    "gini_monthly[\"GINI_MA3\"] = gini_monthly[\"GINI\"].rolling(3, min_periods=2).mean()\n",
    "\n",
    "# 5) Tendencia (regresión lineal simple sobre el índice temporal)\n",
    "#    (ignoramos NaN)\n",
    "mask = gini_monthly[\"GINI\"].notna()\n",
    "x_idx = np.arange(len(gini_monthly))[mask]\n",
    "y_g = gini_monthly.loc[mask, \"GINI\"].values\n",
    "trend = None\n",
    "if len(x_idx) >= 2:\n",
    "    b1, b0 = np.polyfit(x_idx, y_g, 1)  # y = b1*x + b0\n",
    "    trend = (b1, b0)\n",
    "    gini_monthly[\"GINI_TREND\"] = b1*np.arange(len(gini_monthly)) + b0\n",
    "else:\n",
    "    gini_monthly[\"GINI_TREND\"] = np.nan\n",
    "\n",
    "# 6) Gráfico: GINI por mes + MA3 + tendencia\n",
    "plt.figure(figsize=(12,5))\n",
    "plt.plot(gini_monthly[\"periodo_ord\"], gini_monthly[\"GINI\"], marker=\"o\", linewidth=1, label=\"GINI mensual\")\n",
    "plt.plot(gini_monthly[\"periodo_ord\"], gini_monthly[\"GINI_MA3\"], linewidth=2, label=\"GINI móvil 3M\")\n",
    "plt.plot(gini_monthly[\"periodo_ord\"], gini_monthly[\"GINI_TREND\"], linestyle=\"--\", linewidth=2, label=\"Tendencia\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.title(f\"Evolución del GINI por mes – Modelo: {best_model}\")\n",
    "plt.xlabel(\"Periodo\")\n",
    "plt.ylabel(\"GINI\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "print(\"Resumen GINI (mensual):\")\n",
    "print(\"GINI promedio:\", round(gini_monthly[\"GINI\"].mean(skipna=True), 4))\n",
    "print(\"Std GINI:\", round(gini_monthly[\"GINI\"].std(skipna=True), 4))\n",
    "if trend is not None:\n",
    "    print(\"Pendiente tendencia (ΔGINI por mes-índice):\", round(trend[0], 6))\n",
    "\n",
    "# 7) Alertas simples (configurables)\n",
    "# Baseline: promedio de los primeros 3 meses calculables\n",
    "baseline = gini_monthly[\"GINI\"].dropna().head(3).mean() if gini_monthly[\"GINI\"].notna().sum() else np.nan\n",
    "last = gini_monthly[\"GINI\"].dropna().tail(1).values[0] if gini_monthly[\"GINI\"].notna().sum() else np.nan\n",
    "last_ma3 = gini_monthly[\"GINI_MA3\"].dropna().tail(1).values[0] if gini_monthly[\"GINI_MA3\"].notna().sum() else np.nan\n",
    "\n",
    "alerts = []\n",
    "if pd.notnull(baseline) and pd.notnull(last):\n",
    "    drop_abs = baseline - last\n",
    "    drop_rel = drop_abs / max(abs(baseline), 1e-9)\n",
    "    if drop_abs >= 0.05:\n",
    "        alerts.append(f\"ALERTA: caída absoluta de GINI vs baseline >= 0.05 (baseline={baseline:.3f}, last={last:.3f}).\")\n",
    "    if drop_rel >= 0.10:\n",
    "        alerts.append(f\"ALERTA: caída relativa de GINI vs baseline >= 10% (baseline={baseline:.3f}, last={last:.3f}).\")\n",
    "\n",
    "if pd.notnull(last_ma3) and pd.notnull(baseline):\n",
    "    if baseline - last_ma3 >= 0.04:\n",
    "        alerts.append(f\"ALERTA: GINI móvil 3M cayó >= 0.04 vs baseline (baseline={baseline:.3f}, MA3_last={last_ma3:.3f}).\")\n",
    "\n",
    "if trend is not None and trend[0] < -0.002:\n",
    "    alerts.append(f\"ALERTA: tendencia negativa relevante (pendiente={trend[0]:.4f}).\")\n",
    "\n",
    "print(\"\\nAlertas:\")\n",
    "if alerts:\n",
    "    for a in alerts:\n",
    "        print(\"-\", a)\n",
    "else:\n",
    "    print(\"- Sin alertas (según reglas actuales).\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a190229f",
   "metadata": {},
   "source": [
    "## GINI por segmento (diagnóstico localizado)\n",
    "\n",
    "Además del monitoreo global, se recomienda revisar el desempeño **por segmentos** (ej. región, segmento comercial).\n",
    "Esto ayuda a detectar degradación localizada aunque el promedio global se mantenga.\n",
    "\n",
    "A continuación calculamos GINI por `region` y por `segmento` para el **último periodo disponible**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d3174a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "def gini_by_group_last_period(df_in, group_col, score_col=\"score_model\", target_col=TARGET, period_col=\"periodo_ord\", min_n=200):\n",
    "    last_p = df_in[period_col].max()\n",
    "    d = df_in[df_in[period_col] == last_p].copy()\n",
    "\n",
    "    rows = []\n",
    "    for g, x in d.groupby(group_col):\n",
    "        n = len(x)\n",
    "        # AUC requiere 2 clases\n",
    "        if n < min_n or x[target_col].nunique() < 2:\n",
    "            rows.append((g, n, np.nan, np.nan))\n",
    "        else:\n",
    "            auc = roc_auc_score(x[target_col], x[score_col])\n",
    "            rows.append((g, n, auc, gini_from_auc(auc)))\n",
    "    out = pd.DataFrame(rows, columns=[group_col, \"n\", \"AUC\", \"GINI\"]).sort_values(\"GINI\", ascending=False)\n",
    "    return last_p, out\n",
    "\n",
    "for gc in [\"region\", \"segmento\"]:\n",
    "    if gc in df.columns:\n",
    "        last_p, out = gini_by_group_last_period(df, gc, min_n=100)\n",
    "        print(f\"\\n--- GINI por {gc} (último periodo={int(last_p)}) ---\")\n",
    "        display(out.head(20))\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
